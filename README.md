# ğŸš€ æœºå™¨å­¦ä¹ ç ”ç©¶ç¯å¢ƒæ­å»ºæŒ‡å— (Cookbook)

> **ä½œè€…**: Karcen Zheng
> 
> **æœ€åæ›´æ–°**: 2026å¹´1æœˆ

---

## ğŸ“‹ ç›®å½•

1. [æ•°æ®è·å–](#1-æ•°æ®è·å–)
2. [Pythonç¯å¢ƒï¼šAnaconda](#2-pythonç¯å¢ƒanaconda)
3. [æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼šPyTorch](#3-æ·±åº¦å­¦ä¹ æ¡†æ¶pytorch)
4. [æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼šTensorFlow](#4-æ·±åº¦å­¦ä¹ æ¡†æ¶tensorflow)
5. [æ•°å€¼è®¡ç®—ï¼šMATLAB](#5-æ•°å€¼è®¡ç®—matlab)
6. [ç»Ÿè®¡åˆ†æï¼šRè¯­è¨€](#6-ç»Ÿè®¡åˆ†ærè¯­è¨€)
7. [è®¡é‡ç»æµå­¦ï¼šStata](#7-è®¡é‡ç»æµå­¦stata)
8. [ç¤¾ç§‘ç»Ÿè®¡ï¼šIBM SPSS](#8-ç¤¾ç§‘ç»Ÿè®¡ibm-spss)
9. [ç§‘ç ”ç»˜å›¾ï¼šOriginLab](#9-ç§‘ç ”ç»˜å›¾originlab)
10. [åŠå…¬å¥—ä»¶ï¼šMicrosoft Office](#10-åŠå…¬å¥—ä»¶microsoft-office)
11. [å›¾åƒå¤„ç†ï¼šAdobeç³»åˆ—](#11-å›¾åƒå¤„ç†adobeç³»åˆ—)
12. [å­¦æœ¯å†™ä½œï¼šLaTeXä¸Overleaf](#12-å­¦æœ¯å†™ä½œlatexä¸overleaf)
13. [è¿›é˜¶ï¼šæ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ](#13-è¿›é˜¶æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ)
14. [è¿›é˜¶ï¼šæ¶ˆèå®éªŒè®¾è®¡](#14-è¿›é˜¶æ¶ˆèå®éªŒè®¾è®¡)
15. [AIè¾…åŠ©ç¼–ç¨‹å·¥å…·ï¼šTRAE](#15-aiè¾…åŠ©ç¼–ç¨‹å·¥å…·trae)
16. [é™„å½•ï¼šå¸¸ç”¨å‘½ä»¤é€ŸæŸ¥è¡¨](#é™„å½•å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥è¡¨)

---
## 1. æ•°æ®è·å–


æ•°æ®æ˜¯æœºå™¨å­¦ä¹ çš„åŸºçŸ³ã€‚æ ¹æ®**ç¼©æ”¾å®šå¾‹ (Scaling Law)**ï¼Œæ¨¡å‹æ€§èƒ½ä¸æ•°æ®è§„æ¨¡ã€æ¨¡å‹å‚æ•°é‡ã€è®¡ç®—èµ„æºä¹‹é—´å­˜åœ¨å¹‚å¾‹å…³ç³» (power-law relationship)ã€‚åœ¨æ•°æ®ç»´åº¦ä¸Šï¼Œæ¨¡å‹æ€§èƒ½é€šå¸¸éšæ•°æ®é‡ $D$ çš„å¢åŠ å‘ˆ $L\propto D^{-\alpha}$ çš„è§„å¾‹ä¸‹é™ï¼ˆ$L$ ä¸ºæŸå¤±å‡½æ•°ï¼Œ$\alpha$ ä¸ºç¼©æ”¾æŒ‡æ•°ï¼‰ã€‚ç„¶è€Œï¼Œå•çº¯å¢åŠ æ•°æ®é‡å¹¶ä¸è¶³å¤Ÿï¼Œ**æ•°æ®è´¨é‡ (Data Quality)** åŒæ ·å…³é”®â€”â€”é«˜è´¨é‡æ•°æ®åº”å…·å¤‡å‡†ç¡®æ€§ã€å¤šæ ·æ€§ã€ä»£è¡¨æ€§å’Œé«˜ä¿¡å™ªæ¯”ç­‰ç‰¹å¾ã€‚

### Scaling Law æ ¸å¿ƒè¡¨è¿°

Scaling Law çš„ç»å…¸å…¬å¼ï¼ˆKaplan et al., 2020; Hoffmann et al., 2022ï¼‰ï¼š

$$L(N, D, C) = \left(\frac{N_c}{N}\right)^{\alpha_N} + \left(\frac{D_c}{D}\right)^{\alpha_D} + L_\infty$$

å…¶ä¸­ï¼š
- $L$ = æ¨¡å‹æŸå¤±ï¼ˆè¶Šä½è¶Šå¥½ï¼‰
- $N$ = æ¨¡å‹å‚æ•°é‡
- $D$ = æ•°æ®é‡ï¼ˆtokenæ•°ï¼‰
- $C$ = è®¡ç®—é‡ï¼ˆFLOPsï¼‰
- $\alpha_N, \alpha_D$ = ç¼©æ”¾æŒ‡æ•°ï¼ˆçº¦0.07-0.10ï¼‰
- $L_\infty$ = ç†è®ºä¸‹ç•Œ

**å…³é”®ç»“è®ºï¼š** æ•°æ®é‡ç¿»å€ï¼ŒæŸå¤±ä¸‹é™çº¦ 5-7%ï¼Œä½†å­˜åœ¨è¾¹é™…é€’å‡æ•ˆåº”ã€‚

---

### "æ•°æ®è´¨é‡"çš„ä¸“ä¸šå®šä¹‰

| ç»´åº¦ | è‹±æ–‡ | å®šä¹‰ | åº¦é‡æ–¹æ³• |
|------|------|------|----------|
| **å‡†ç¡®æ€§** | Accuracy | æ•°æ®ä¸çœŸå®å€¼çš„ç¬¦åˆç¨‹åº¦ | é”™è¯¯ç‡ã€æ ‡æ³¨ä¸€è‡´æ€§ |
| **å®Œæ•´æ€§** | Completeness | æ— ç¼ºå¤±å€¼ã€æ— ç©ºç™½å­—æ®µ | ç¼ºå¤±ç‡ |
| **ä¸€è‡´æ€§** | Consistency | æ•°æ®æ ¼å¼ã€å•ä½ç»Ÿä¸€ | å†²çªè®°å½•æ¯”ä¾‹ |
| **æ—¶æ•ˆæ€§** | Timeliness | æ•°æ®çš„æ–°é²œç¨‹åº¦ | æ•°æ®å¹´é¾„ |
| **ç›¸å…³æ€§** | Relevance | ä¸ç›®æ ‡ä»»åŠ¡çš„ç›¸å…³ç¨‹åº¦ | ç‰¹å¾é‡è¦æ€§ |
| **å¤šæ ·æ€§** | Diversity | è¦†ç›–ä¸åŒåœºæ™¯/åˆ†å¸ƒ | ç†µã€åˆ†å¸ƒè¦†ç›–ç‡ |
| **ä»£è¡¨æ€§** | Representativeness | æ ·æœ¬èƒ½ä»£è¡¨æ€»ä½“ | åˆ†å¸ƒåå·® |
| **ä¿¡å™ªæ¯”** | Signal-to-Noise Ratio | æœ‰æ•ˆä¿¡æ¯vså™ªå£° | SNR |

---

> æ•°æ®è·å–æ˜¯æœºå™¨å­¦ä¹ æµç¨‹çš„é¦–è¦ç¯èŠ‚ã€‚æ ¹æ®ç¥ç»ç½‘ç»œç¼©æ”¾å®šå¾‹ (Neural Scaling Laws)ï¼Œæ¨¡å‹æ€§èƒ½ï¼ˆä»¥äº¤å‰ç†µæŸå¤±è¡¡é‡ï¼‰ä¸è®­ç»ƒæ•°æ®é‡ä¹‹é—´å­˜åœ¨å¹‚å¾‹å…³ç³»ï¼š$L \propto D^{-\alpha}$ï¼Œå…¶ä¸­ $\alpha \approx 0.095$ï¼ˆHoffmann et al., 2022ï¼‰ã€‚è¿™æ„å‘³ç€æ•°æ®é‡æ¯å¢åŠ ä¸€ä¸ªæ•°é‡çº§ï¼Œæ¨¡å‹æŸå¤±å¯é™ä½çº¦20%ã€‚ç„¶è€Œï¼Œç¼©æ”¾å®šå¾‹çš„å‰ææ˜¯æ•°æ®è´¨é‡å¾—åˆ°ä¿è¯ã€‚é«˜è´¨é‡æ•°æ®é›†åº”æ»¡è¶³ä»¥ä¸‹æ ‡å‡†ï¼š(1) **å‡†ç¡®æ€§**ï¼šæ ‡æ³¨æ­£ç¡®ã€æ— ç³»ç»Ÿæ€§åå·®ï¼›(2) **å¤šæ ·æ€§**ï¼šè¦†ç›–ç›®æ ‡åˆ†å¸ƒçš„å„ä¸ªå­ç©ºé—´ï¼›(3) **ä»£è¡¨æ€§**ï¼šæ ·æœ¬åˆ†å¸ƒä¸çœŸå®åº”ç”¨åœºæ™¯ä¸€è‡´ï¼›(4) **é«˜ä¿¡å™ªæ¯”**ï¼šæœ‰æ•ˆä¿¡æ¯å æ¯”é«˜ã€å†—ä½™å’Œå™ªå£°å°‘ã€‚ä½è´¨é‡æ•°æ®ä¸ä»…æ— æ³•å¸¦æ¥ç¼©æ”¾æ”¶ç›Šï¼Œç”šè‡³å¯èƒ½å¯¼è‡´æ¨¡å‹å­¦ä¹ åˆ°é”™è¯¯æ¨¡å¼ã€‚

### æœ¬ Cookbook æ•°æ®è·å–å…·ä½“çš„æ“ä½œæ­¥éª¤
[Bing](www.bing.com) æœç´¢ `ä¸­å›½è€ƒç ”äººæ•°ç»Ÿè®¡`ï¼Œé€‰æ‹© [å†å¹´è€ƒç ”æŠ¥åäººæ•°ç»Ÿè®¡ï¼ˆå«2005-2026å¹´ï¼‰_å¤§å­¦ç”Ÿå¿…å¤‡ç½‘](https://www.dxsbb.com/news/124228.html) æ‰¾åˆ°å†å¹´`è€ƒç ”äººæ•°æ•°æ®`ã€‚

![bing_search.png](bing_search.png)



![kaoyan_data.png](kaoyan_data.png)

| å¹´ä»½ | æŠ¥åäººæ•° | å¢é•¿ç‡   |
|:----:|:--------:|:--------:|
| 2005 | 117.2ä¸‡  | 24.02%   |
| 2006 | 127.1ä¸‡  | 8.79%    |
| 2007 | 128.2ä¸‡  | 0.55%    |
| 2008 | 120ä¸‡    | -6.40%   |
| 2009 | 124.6ä¸‡  | 3.83%    |
| 2010 | 140.6ä¸‡  | 12.84%   |
| 2011 | 151.1ä¸‡  | 7.47%    |
| 2012 | 165.6ä¸‡  | 9.60%    |
| 2013 | 176ä¸‡    | 6.28%    |
| 2014 | 172ä¸‡    | -2.27%   |
| 2015 | 164.9ä¸‡  | -4.07%   |
| 2016 | 177ä¸‡    | 7.27%    |
| 2017 | 201ä¸‡    | 13.56%   |
| 2018 | 238ä¸‡    | 18.41%   |
| 2019 | 290ä¸‡    | 21.85%   |
| 2020 | 341ä¸‡    | 17.59%   |
| 2021 | 377ä¸‡    | 10.56%   |
| 2022 | 457ä¸‡    | 21.22%   |
| 2023 | 474ä¸‡    | 3.72%    |
| 2024 | 438ä¸‡    | -7.59%   |
| 2025 | 388ä¸‡    | -11.40%  |
| 2026 | 343ä¸‡    | -11.60%  |

> åŸå§‹çš„æ•°æ®æ˜¯æ—¶é—´å€’åºçš„ï¼Œæˆ‘æŠŠæ•°æ®ç”¨ `Excel` çš„ `sort by` åŠŸèƒ½å¤„ç†æˆæ—¶é—´æ­£åºæ•°æ®ï¼Œç¬¦åˆæˆ‘ä»¬çš„è®¤çŸ¥ä¹ æƒ¯ã€‚
> é€‰æ‹©éœ€è¦ `sort` çš„æ•°æ®ï¼Œæ‰§è¡Œ `sort` å°±è¡Œ
> ![excel_sort_by.png](excel_sort_by.png)

---

---

## 2. Pythonç¯å¢ƒï¼šAnaconda

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | Pythonå‘è¡Œç‰ˆï¼Œç”¨äºæ•°æ®åˆ†æã€ç§‘å­¦è®¡ç®—ã€æœºå™¨å­¦ä¹  |
| **è´¹ç”¨** | âœ… å…è´¹ |
| **å®˜ç½‘** | https://www.anaconda.com/download |

Anacondaé¢„è£…äº†NumPyã€pandasã€matplotlibã€scikit-learnç­‰å¸¸ç”¨åº“ï¼Œå¹¶æä¾›å¼ºå¤§çš„ç¯å¢ƒç®¡ç†åŠŸèƒ½ï¼Œé¿å…ä¸åŒé¡¹ç›®ä¹‹é—´çš„ä¾èµ–å†²çªã€‚

### ğŸ”§ å®‰è£…æ­¥éª¤

**Windows/macOS:**
1. è®¿é—®å®˜ç½‘ä¸‹è½½å¯¹åº”ç³»ç»Ÿçš„å®‰è£…åŒ…
2. åŒå‡»è¿è¡Œå®‰è£…ç¨‹åº
3. å»ºè®®å‹¾é€‰"Add Anaconda to PATH"ï¼ˆWindowsï¼‰
4. å®‰è£…å®Œæˆåï¼Œæ‰“å¼€ç»ˆç«¯è¾“å…¥ `conda --version` éªŒè¯

**Linux:**
```bash
# ä¸‹è½½å®‰è£…è„šæœ¬
wget https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh

# è¿è¡Œå®‰è£…
bash Anaconda3-2024.10-1-Linux-x86_64.sh

# åˆå§‹åŒ–
source ~/.bashrc
conda --version
```

### ğŸ“ å…·ä½“ç¤ºä¾‹ï¼šåˆ›å»ºæœºå™¨å­¦ä¹ é¡¹ç›®ç¯å¢ƒå¹¶åˆ†ææ•°æ®

```bash
# åˆ›å»ºåä¸º "ml_project" çš„æ–°ç¯å¢ƒï¼ŒæŒ‡å®šPythonç‰ˆæœ¬
conda create -n ml_project python=3.10

# æ¿€æ´»ç¯å¢ƒ
conda activate ml_project

# å®‰è£…å¸¸ç”¨æ•°æ®ç§‘å­¦åº“
conda install numpy pandas matplotlib scikit-learn jupyter seaborn

# æŸ¥çœ‹å·²å®‰è£…çš„åŒ…
conda list

# å¯¼å‡ºç¯å¢ƒé…ç½®ï¼ˆæ–¹ä¾¿ä»–äººå¤ç°ï¼‰
conda env export > environment.yml

# ä»é…ç½®æ–‡ä»¶åˆ›å»ºç¯å¢ƒ
conda env create -f environment.yml

# é€€å‡ºå½“å‰ç¯å¢ƒ
conda deactivate
```

**å®æˆ˜ï¼šåˆ†æä¸­å›½è€ƒç ”å†å¹´æŠ¥åäººæ•°**

![è€ƒç ”æ•°æ®åˆ†æ](kaoyan_analysis.png)
*å›¾1ï¼šä¸­å›½è€ƒç ”æŠ¥åäººæ•°è¶‹åŠ¿åˆ†æï¼ˆ2005-2026ï¼‰*

```python
"""
ä½¿ç”¨pandaså’Œmatplotlibåˆ†æä¸­å›½è€ƒç ”å†å¹´æŠ¥åäººæ•°è¶‹åŠ¿
æ–‡ä»¶ï¼škaoyan_analysis.py
"""

import numpy as np
import matplotlib.pyplot as plt

# ============== æ•°æ®å‡†å¤‡ ==============
# ä¸­å›½è€ƒç ”å†å¹´æŠ¥åäººæ•°ï¼ˆå•ä½ï¼šä¸‡äººï¼‰
years = np.array([2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,
                  2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026])
enrollment = np.array([117.2, 127.1, 128.2, 120, 124.6, 140.6, 151.1, 165.6, 176, 172,
                       164.9, 177, 201, 238, 290, 341, 377, 457, 474, 438, 388, 343])
growth_rate = np.array([24.02, 8.79, 0.55, -6.40, 3.83, 12.84, 7.47, 9.60, 6.28, -2.27,
                        -4.07, 7.27, 13.56, 18.41, 21.85, 17.59, 10.56, 21.22, 3.72, -7.59, -11.4, -11.6])

# ============== å¯è§†åŒ–ï¼ˆ2x2å››å­å›¾ï¼‰ ==============
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# å­å›¾1ï¼šæŠ¥åäººæ•°è¶‹åŠ¿
ax1 = axes[0, 0]
ax1.plot(years, enrollment, 'b-o', linewidth=2, markersize=6)
ax1.fill_between(years, enrollment, alpha=0.3)
ax1.axvline(x=2023, color='red', linestyle='--', alpha=0.7, label='Peak (2023)')
ax1.set_xlabel('Year', fontsize=12)
ax1.set_ylabel('Enrollment (10k persons)', fontsize=12)
ax1.set_title('Graduate Exam Enrollment Trend (2005-2026)', fontsize=13, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)
# æ ‡æ³¨å³°å€¼
peak_idx = np.argmax(enrollment)
ax1.annotate(f'Peak: {enrollment[peak_idx]}', 
             xy=(years[peak_idx], enrollment[peak_idx]),
             xytext=(years[peak_idx]-3, enrollment[peak_idx]+20),
             fontsize=10, color='red',
             arrowprops=dict(arrowstyle='->', color='red'))

# å­å›¾2ï¼šå¢é•¿ç‡ï¼ˆç»¿è‰²æ­£ã€çº¢è‰²è´Ÿï¼‰
ax2 = axes[0, 1]
colors = ['#2ecc71' if x >= 0 else '#e74c3c' for x in growth_rate]
ax2.bar(years, growth_rate, color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)
ax2.axhline(y=0, color='black', linewidth=1)
ax2.set_xlabel('Year', fontsize=12)
ax2.set_ylabel('Growth Rate (%)', fontsize=12)
ax2.set_title('Year-over-Year Growth Rate', fontsize=13, fontweight='bold')
ax2.grid(True, alpha=0.3, axis='y')

# å­å›¾3ï¼šé˜¶æ®µåˆ’åˆ†
ax3 = axes[1, 0]
phases = [
    ('2005-2015\nSteady', enrollment[(years>=2005) & (years<=2015)].mean(), '#3498db'),
    ('2016-2019\nRapid Growth', enrollment[(years>=2016) & (years<=2019)].mean(), '#2ecc71'),
    ('2020-2023\nPeak', enrollment[(years>=2020) & (years<=2023)].mean(), '#f39c12'),
    ('2024-2026\nDecline', enrollment[(years>=2024) & (years<=2026)].mean(), '#e74c3c'),
]
bars = ax3.bar([p[0] for p in phases], [p[1] for p in phases], 
               color=[p[2] for p in phases], edgecolor='black', alpha=0.8)
ax3.set_ylabel('Average Enrollment (10k)', fontsize=12)
ax3.set_title('Enrollment by Period', fontsize=13, fontweight='bold')
for bar, (_, val, _) in zip(bars, phases):
    ax3.text(bar.get_x() + bar.get_width()/2, val + 5, f'{val:.0f}', 
             ha='center', fontsize=11, fontweight='bold')

# å­å›¾4ï¼šå¢é•¿ç‡çš„å˜åŒ–è¶‹åŠ¿ï¼ˆäºŒé˜¶å¯¼æ•°ï¼‰
ax4 = axes[1, 1]
growth_change = np.diff(growth_rate)
ax4.plot(years[1:], growth_change, 'purple', marker='s', linewidth=2, markersize=5)
ax4.axhline(y=0, color='gray', linestyle='--')
ax4.fill_between(years[1:], growth_change, 0, 
                  where=(growth_change < 0), color='red', alpha=0.3, label='Decelerating')
ax4.fill_between(years[1:], growth_change, 0, 
                  where=(growth_change >= 0), color='green', alpha=0.3, label='Accelerating')
ax4.set_xlabel('Year', fontsize=12)
ax4.set_ylabel('Change in Growth Rate (%)', fontsize=12)
ax4.set_title('Growth Acceleration/Deceleration', fontsize=13, fontweight='bold')
ax4.legend(fontsize=9)
ax4.grid(True, alpha=0.3)

plt.tight_layout()
# ä¿å­˜ä¸ºå¤šç§æ ¼å¼ï¼ˆæ³¨æ„æ˜¾å¼è®¾ç½®dpiï¼‰
plt.savefig('kaoyan_analysis.png', dpi=300, bbox_inches='tight')
plt.savefig('kaoyan_analysis.pdf', bbox_inches='tight')
plt.savefig('kaoyan_analysis.svg', bbox_inches='tight')
plt.show()
```

---

## 3. æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼šPyTorch

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ”¯æŒåŠ¨æ€è®¡ç®—å›¾ï¼Œå­¦æœ¯ç ”ç©¶é¦–é€‰ |
| **è´¹ç”¨** | âœ… å…è´¹å¼€æº |
| **å®˜ç½‘** | https://pytorch.org |

PyTorchä»¥å…¶ç›´è§‚çš„APIå’ŒåŠ¨æ€è®¡ç®—å›¾æœºåˆ¶ï¼Œæˆä¸ºå­¦æœ¯ç•Œæœ€æµè¡Œçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚

### ğŸ”§ å®‰è£…æ­¥éª¤

```bash
conda activate ml_project

# CPUç‰ˆæœ¬
conda install pytorch torchvision torchaudio cpuonly -c pytorch

# GPUç‰ˆæœ¬ï¼ˆCUDA 11.8ï¼‰
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# éªŒè¯
python -c "import torch; print(f'PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

### ğŸ“ å…·ä½“ç¤ºä¾‹ï¼šLSTMé¢„æµ‹æ—¶é—´åºåˆ—

LSTM (Long Short-Term Memory) æ˜¯ä¸€ç§ç‰¹æ®Šçš„å¾ªç¯ç¥ç»ç½‘ç»œï¼Œæ“…é•¿å¤„ç†æ—¶é—´åºåˆ—æ•°æ®ã€‚

```python
"""
PyTorch LSTMæ—¶é—´åºåˆ—é¢„æµ‹ç¤ºä¾‹
"""

import torch
import torch.nn as nn

# å®šä¹‰LSTMæ¨¡å‹
class LSTMPredictor(nn.Module):
    def __init__(self, input_size=1, hidden_size=64, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
    
    def forward(self, x):
        # x: (batch, seq_len, input_size)
        lstm_out, _ = self.lstm(x)
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        out = self.fc(lstm_out[:, -1, :])
        return out

# ä½¿ç”¨ç¤ºä¾‹
model = LSTMPredictor()
x = torch.randn(32, 10, 1)  # batch=32, seq_len=10, features=1
output = model(x)
print(f"è¾“å…¥å½¢çŠ¶: {x.shape}, è¾“å‡ºå½¢çŠ¶: {output.shape}")
```

---

## 4. æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼šTensorFlow

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ŒGoogleå¼€å‘ï¼Œå·¥ä¸šéƒ¨ç½²å‹å¥½ |
| **è´¹ç”¨** | âœ… å…è´¹å¼€æº |
| **å®˜ç½‘** | https://www.tensorflow.org |

### ğŸ”§ å®‰è£…æ­¥éª¤

```bash
conda activate ml_project

# CPUç‰ˆæœ¬
pip install tensorflow

# GPUç‰ˆæœ¬
pip install tensorflow[and-cuda]

# éªŒè¯
python -c "import tensorflow as tf; print(f'TensorFlow {tf.__version__}')"
```

### ğŸ“ å…·ä½“ç¤ºä¾‹ï¼šé«˜æ–¯è¿‡ç¨‹å›å½’é¢„æµ‹ï¼ˆGPRï¼‰

> **è¿™æ˜¯æœ¬æ–‡çš„æ ¸å¿ƒç¤ºä¾‹**ï¼šç”¨2005-2023å¹´æ•°æ®é¢„æµ‹2024-2026å¹´çš„è€ƒç ”äººæ•°

é«˜æ–¯è¿‡ç¨‹å›å½’(GPR)æ˜¯ä¸€ç§éå‚æ•°è´å¶æ–¯æ–¹æ³•ï¼Œç‰¹åˆ«é€‚åˆ**å°æ ·æœ¬ã€éœ€è¦ä¸ç¡®å®šæ€§é‡åŒ–**çš„åœºæ™¯ã€‚

![GPRé¢„æµ‹ç»“æœ](gpr_prediction.png)
*å›¾2ï¼šé«˜æ–¯è¿‡ç¨‹å›å½’é¢„æµ‹è€ƒç ”æŠ¥åäººæ•°ï¼ˆå«95%ç½®ä¿¡åŒºé—´ï¼‰*

```python
"""
é«˜æ–¯è¿‡ç¨‹å›å½’(GPR)é¢„æµ‹è€ƒç ”æŠ¥åäººæ•°
æ–‡ä»¶ï¼šgpr_prediction.py

ä»»åŠ¡ï¼šç”¨2005-2023å¹´æ•°æ®ï¼ˆè®­ç»ƒé›†ï¼‰é¢„æµ‹2024-2026å¹´ï¼ˆæµ‹è¯•é›†ï¼‰
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

# ============== 1. æ•°æ®å‡†å¤‡ ==============
# è®­ç»ƒæ•°æ®ï¼š2005-2023ï¼ˆ19ä¸ªæ ·æœ¬ï¼‰
train_years = np.array([2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,
                        2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023])
train_values = np.array([117.2, 127.1, 128.2, 120, 124.6, 140.6, 151.1, 165.6, 176, 172,
                         164.9, 177, 201, 238, 290, 341, 377, 457, 474])

# æµ‹è¯•æ•°æ®ï¼š2024-2026ï¼ˆçœŸå®å€¼ï¼Œç”¨äºè¯„ä¼°ï¼‰
test_years = np.array([2024, 2025, 2026])
test_values = np.array([438, 388, 343])

# æ•°æ®æ ‡å‡†åŒ–ï¼ˆGPRå¯¹å°ºåº¦æ•æ„Ÿï¼‰
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_train = scaler_X.fit_transform(train_years.reshape(-1, 1))
y_train = scaler_y.fit_transform(train_values.reshape(-1, 1)).flatten()
X_test = scaler_X.transform(test_years.reshape(-1, 1))

# ============== 2. å®šä¹‰æ ¸å‡½æ•° ==============
# æ ¸å‡½æ•°å†³å®šäº†GPRå‡è®¾æ•°æ®çš„å¹³æ»‘ç¨‹åº¦å’Œå˜åŒ–æ¨¡å¼
# RBF: å¾„å‘åŸºå‡½æ•°ï¼Œå‡è®¾å¹³æ»‘å˜åŒ–
# Matern: æ›´çµæ´»ï¼Œèƒ½æ•æ‰å±€éƒ¨å˜åŒ–
# WhiteKernel: å¤„ç†è§‚æµ‹å™ªå£°
kernel = (
    1.0 * RBF(length_scale=1.0, length_scale_bounds=(0.1, 10.0)) +
    1.0 * Matern(length_scale=1.0, nu=2.5) +
    WhiteKernel(noise_level=0.1)
)

# ============== 3. è®­ç»ƒGPRæ¨¡å‹ ==============
gpr = GaussianProcessRegressor(
    kernel=kernel,
    n_restarts_optimizer=20,  # å¤šæ¬¡é‡å¯ä¼˜åŒ–ï¼Œé¿å…å±€éƒ¨æœ€ä¼˜
    random_state=42
)
gpr.fit(X_train, y_train)

# ============== 4. é¢„æµ‹ ==============
# GPRçš„ä¼˜åŠ¿ï¼šåŒæ—¶è¿”å›é¢„æµ‹å‡å€¼å’Œæ ‡å‡†å·®ï¼ˆä¸ç¡®å®šæ€§ï¼‰
y_pred_scaled, y_std_scaled = gpr.predict(X_test, return_std=True)

# åæ ‡å‡†åŒ–
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
y_std = y_std_scaled * scaler_y.scale_[0]

# ç”Ÿæˆå¹³æ»‘é¢„æµ‹æ›²çº¿
all_years = np.arange(2005, 2030)
X_all = scaler_X.transform(all_years.reshape(-1, 1))
y_all_pred, y_all_std = gpr.predict(X_all, return_std=True)
y_all_pred = scaler_y.inverse_transform(y_all_pred.reshape(-1, 1)).flatten()
y_all_std = y_all_std * scaler_y.scale_[0]

# ============== 5. è¯„ä¼° ==============
rmse = np.sqrt(mean_squared_error(test_values, y_pred))
mae = mean_absolute_error(test_values, y_pred)

print(f"é¢„æµ‹ç»“æœ:")
for yr, true, pred, std in zip(test_years, test_values, y_pred, y_std):
    print(f"  {yr}: çœŸå®={true:.0f}, é¢„æµ‹={pred:.0f}Â±{1.96*std:.0f}")
print(f"\nRMSE: {rmse:.1f}ä¸‡äºº, MAE: {mae:.1f}ä¸‡äºº")

# ============== 6. å¯è§†åŒ–ï¼ˆ1x2ä¸¤å­å›¾ï¼‰ ==============
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# å·¦å›¾ï¼šå®Œæ•´é¢„æµ‹
ax1 = axes[0]
ax1.plot(train_years, train_values, 'bo-', label='Training (2005-2023)', markersize=6)
ax1.plot(test_years, test_values, 'gs-', label='Actual (2024-2026)', markersize=10, linewidth=2)
ax1.plot(all_years, y_all_pred, 'r-', label='GPR Prediction', linewidth=2)
ax1.fill_between(all_years, y_all_pred - 1.96*y_all_std, y_all_pred + 1.96*y_all_std,
                  color='red', alpha=0.2, label='95% CI')
ax1.axvline(x=2023.5, color='gray', linestyle=':', alpha=0.7)
ax1.scatter(test_years, y_pred, color='red', s=100, zorder=5, marker='^', edgecolor='black')
ax1.set_xlabel('Year', fontsize=12)
ax1.set_ylabel('Enrollment (10k persons)', fontsize=12)
ax1.set_title(f'GPR Prediction: RMSE={rmse:.1f}, MAE={mae:.1f}', fontsize=13, fontweight='bold')
ax1.legend(loc='upper left', fontsize=9)
ax1.grid(True, alpha=0.3)
ax1.set_xlim(2004, 2030)

# å³å›¾ï¼šæ”¾å¤§æµ‹è¯•åŒºåŸŸ
ax2 = axes[1]
years_zoom = np.arange(2018, 2028)
X_zoom = scaler_X.transform(years_zoom.reshape(-1, 1))
y_zoom_pred, y_zoom_std = gpr.predict(X_zoom, return_std=True)
y_zoom_pred = scaler_y.inverse_transform(y_zoom_pred.reshape(-1, 1)).flatten()
y_zoom_std = y_zoom_std * scaler_y.scale_[0]

hist_mask = (train_years >= 2018)
ax2.plot(train_years[hist_mask], train_values[hist_mask], 'bo-', label='Training', markersize=8)
ax2.plot(test_years, test_values, 'gs-', label='Actual', markersize=12, linewidth=2)
ax2.plot(years_zoom, y_zoom_pred, 'r-', label='GPR', linewidth=2)
ax2.fill_between(years_zoom, y_zoom_pred - 1.96*y_zoom_std, y_zoom_pred + 1.96*y_zoom_std,
                  color='red', alpha=0.2)
ax2.scatter(test_years, y_pred, color='red', s=120, zorder=5, marker='^', edgecolor='black')
ax2.axvline(x=2023.5, color='gray', linestyle=':', alpha=0.7)
ax2.set_xlabel('Year', fontsize=12)
ax2.set_ylabel('Enrollment (10k persons)', fontsize=12)
ax2.set_title('Zoomed View (2018-2027)', fontsize=13, fontweight='bold')
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('gpr_prediction.png', dpi=300, bbox_inches='tight')
plt.savefig('gpr_prediction.pdf', bbox_inches='tight')
plt.savefig('gpr_prediction.svg', bbox_inches='tight')
plt.show()
```

---

## 5. æ•°å€¼è®¡ç®—ï¼šMATLAB

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | æ•°å€¼è®¡ç®—ã€å·¥ç¨‹ä»¿çœŸã€ä¿¡å·å¤„ç† |
| **è´¹ç”¨** | ğŸ’° ä»˜è´¹ï¼ˆå­¦æ ¡é€šå¸¸æä¾›æ ¡å›­æˆæƒï¼‰ |
| **å®˜ç½‘** | https://www.mathworks.com |

### ğŸ”§ å®‰è£…æ­¥éª¤
1. æ£€æŸ¥å­¦æ ¡æ˜¯å¦æä¾›MATLABæ ¡å›­ç‰ˆæˆæƒ
2. ä½¿ç”¨ `.edu` é‚®ç®±ç™»å½•MathWorksè´¦æˆ·
3. ä¸‹è½½å®‰è£…åŒ…å¹¶æ¿€æ´»

### ğŸ“ å…·ä½“ç¤ºä¾‹ï¼šçŸ©é˜µè¿ç®—ä¸å¯è§†åŒ–

```matlab
% æ–‡ä»¶ï¼šexample.m
% MATLABåŸºç¡€ç¤ºä¾‹

% åˆ›å»ºçŸ©é˜µ
A = [1 2 3; 4 5 6; 7 8 9];
B = rand(3, 3);

% çŸ©é˜µè¿ç®—
C = A * B;           % çŸ©é˜µä¹˜æ³•
D = A .* B;          % å…ƒç´ ä¹˜æ³•
E = inv(A + eye(3)); % æ±‚é€†

% ç‰¹å¾å€¼åˆ†è§£
[V, D] = eig(A);

% å¯è§†åŒ–
x = linspace(0, 2*pi, 100);
y = sin(x);
plot(x, y, 'b-', 'LineWidth', 2);
xlabel('x'); ylabel('sin(x)');
title('Sine Function');
saveas(gcf, 'matlab_plot.png');
```

---

## 6. ç»Ÿè®¡åˆ†æï¼šRè¯­è¨€

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | ç»Ÿè®¡åˆ†æã€æ•°æ®å¯è§†åŒ–ã€å­¦æœ¯ç ”ç©¶ |
| **è´¹ç”¨** | âœ… å…è´¹å¼€æº |
| **å®˜ç½‘** | https://www.r-project.org |

### ğŸ”§ å®‰è£…æ­¥éª¤
```bash
# Ubuntu/Debian
sudo apt install r-base

# macOS (ä½¿ç”¨Homebrew)
brew install r

# æ¨èå®‰è£…RStudio IDE
# https://posit.co/download/rstudio-desktop/
```

### ğŸ“ å…·ä½“ç¤ºä¾‹ï¼šçº¿æ€§å›å½’åˆ†æ

```r
# æ–‡ä»¶ï¼šregression.R
# Rè¯­è¨€çº¿æ€§å›å½’ç¤ºä¾‹

# åˆ›å»ºæ•°æ®
years <- 2005:2023
enrollment <- c(117.2, 127.1, 128.2, 120, 124.6, 140.6, 151.1, 165.6, 
                176, 172, 164.9, 177, 201, 238, 290, 341, 377, 457, 474)

# çº¿æ€§å›å½’
model <- lm(enrollment ~ years)
summary(model)

# å¯è§†åŒ–
pdf("r_regression.pdf", width=8, height=6)
plot(years, enrollment, pch=19, col="blue",
     main="Linear Regression", xlab="Year", ylab="Enrollment")
abline(model, col="red", lwd=2)
legend("topleft", legend=c("Data", "Fitted"), 
       col=c("blue", "red"), pch=c(19, NA), lty=c(NA, 1))
dev.off()
```

---

## 7. è®¡é‡ç»æµå­¦ï¼šStata

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | è®¡é‡ç»æµå­¦ã€ç¤¾ä¼šç§‘å­¦ç»Ÿè®¡ |
| **è´¹ç”¨** | ğŸ’° ä»˜è´¹ï¼ˆå­¦æ ¡å¯èƒ½æœ‰æˆæƒï¼‰ |
| **å®˜ç½‘** | https://www.stata.com |

### ğŸ“ å…·ä½“ç¤ºä¾‹

```stata
* å¯¼å…¥æ•°æ®
import delimited "data.csv", clear

* æè¿°ç»Ÿè®¡
summarize enrollment

* å›å½’åˆ†æ
regress enrollment year

* å¯¼å‡ºç»“æœ
esttab using "results.rtf", replace
```

---

## 8. ç¤¾ç§‘ç»Ÿè®¡ï¼šIBM SPSS

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | é—®å·åˆ†æã€ç¤¾ä¼šç§‘å­¦ç»Ÿè®¡ |
| **è´¹ç”¨** | ğŸ’° ä»˜è´¹ï¼ˆå­¦æ ¡å¯èƒ½æœ‰æˆæƒï¼‰ |
| **å®˜ç½‘** | https://www.ibm.com/spss |

### ğŸ“ ä½¿ç”¨æµç¨‹
1. **æ•°æ®å¯¼å…¥**ï¼šFile â†’ Open â†’ Data
2. **æè¿°ç»Ÿè®¡**ï¼šAnalyze â†’ Descriptive Statistics â†’ Frequencies
3. **å›å½’åˆ†æ**ï¼šAnalyze â†’ Regression â†’ Linear
4. **å›¾è¡¨å¯¼å‡º**ï¼šåŒå‡»å›¾è¡¨ â†’ File â†’ Export


### IBM SPSS çº¿æ€§å›å½’å®Œå…¨æŒ‡å—

#### ğŸ“Œ ç®€ä»‹

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | é—®å·åˆ†æã€ç¤¾ä¼šç§‘å­¦ç»Ÿè®¡ã€åŒ»å­¦ç ”ç©¶ |
| **è´¹ç”¨** | ğŸ’° ä»˜è´¹ï¼ˆå­¦æ ¡å¯èƒ½æœ‰æˆæƒï¼‰ |
| **å®˜ç½‘** | https://www.ibm.com/spss |

SPSS (Statistical Package for the Social Sciences) æ˜¯ç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­æœ€å¸¸ç”¨çš„ç»Ÿè®¡è½¯ä»¶ï¼Œä»¥å…¶å‹å¥½çš„å›¾å½¢ç•Œé¢è‘—ç§°ã€‚

---

#### ğŸ“ ç¤ºä¾‹æ•°æ®ï¼šå‘˜å·¥è–ªèµ„å½±å“å› ç´ ç ”ç©¶

å‡è®¾æˆ‘ä»¬ç ”ç©¶**å‘˜å·¥å¹´è–ª**çš„å½±å“å› ç´ ï¼Œæ”¶é›†äº†200åå‘˜å·¥çš„æ•°æ®ï¼š

| å˜é‡å | å«ä¹‰ | ç±»å‹ | è¯´æ˜ |
|--------|------|------|------|
| `salary` | å¹´è–ªï¼ˆä¸‡å…ƒï¼‰ | å› å˜é‡ | è¿ç»­å˜é‡ |
| `edu_years` | å—æ•™è‚²å¹´é™ | è‡ªå˜é‡ | è¿ç»­å˜é‡ï¼ˆ12-22å¹´ï¼‰ |
| `experience` | å·¥ä½œç»éªŒï¼ˆå¹´ï¼‰ | è‡ªå˜é‡ | è¿ç»­å˜é‡ï¼ˆ0-30å¹´ï¼‰ |
| `age` | å¹´é¾„ | è‡ªå˜é‡ | è¿ç»­å˜é‡ï¼ˆ22-55å²ï¼‰ |
| `gender` | æ€§åˆ« | è‡ªå˜é‡ | è™šæ‹Ÿå˜é‡ï¼ˆ0=å¥³ï¼Œ1=ç”·ï¼‰ |
| `department` | éƒ¨é—¨ | è‡ªå˜é‡ | åˆ†ç±»å˜é‡ï¼ˆ1=æŠ€æœ¯ï¼Œ2=é”€å”®ï¼Œ3=ç®¡ç†ï¼‰ |
| `performance` | ç»©æ•ˆè¯„åˆ† | è‡ªå˜é‡ | è¿ç»­å˜é‡ï¼ˆ1-10åˆ†ï¼‰ |
| `training_hours` | åŸ¹è®­æ—¶é•¿ï¼ˆå°æ—¶/å¹´ï¼‰ | è‡ªå˜é‡ | è¿ç»­å˜é‡ |
| `overtime` | åŠ ç­æ—¶é•¿ï¼ˆå°æ—¶/æœˆï¼‰ | è‡ªå˜é‡ | è¿ç»­å˜é‡ |

**ç ”ç©¶é—®é¢˜**ï¼šå“ªäº›å› ç´ æ˜¾è‘—å½±å“å‘˜å·¥è–ªèµ„ï¼Ÿå„å› ç´ çš„å½±å“ç¨‹åº¦å¦‚ä½•ï¼Ÿ

---

#### ğŸ”§ SPSS çº¿æ€§å›å½’æ“ä½œæ­¥éª¤

##### åŸºæœ¬æ“ä½œè·¯å¾„

```
Analyze â†’ Regression â†’ Linear...
```

##### ç•Œé¢è®¾ç½®

1. **Dependentï¼ˆå› å˜é‡ï¼‰**ï¼šå°† `salary` æ‹–å…¥
2. **Independent(s)ï¼ˆè‡ªå˜é‡ï¼‰**ï¼šå°†å€™é€‰å˜é‡æ‹–å…¥
3. **Methodï¼ˆæ–¹æ³•ï¼‰**ï¼šé€‰æ‹©å›å½’æ–¹æ³•ï¼ˆé‡ç‚¹ï¼ï¼‰
4. **Statistics**ï¼šå‹¾é€‰ `Estimates`, `Model fit`, `R squared change`, `Collinearity diagnostics`
5. **Plots**ï¼šå‹¾é€‰ `Histogram`, `Normal probability plot`ï¼ˆæ£€éªŒæ®‹å·®æ­£æ€æ€§ï¼‰


#### ğŸ¯ SPSS çº¿æ€§å›å½’ 6 ç§æ–¹æ³•è¯¦è§£

##### æ–¹æ³•æ€»è§ˆ

| æ–¹æ³• | è‹±æ–‡ | æ ¸å¿ƒé€»è¾‘ | é€‚ç”¨åœºæ™¯ | é£é™© |
|------|------|----------|----------|------|
| **Enter** | å¼ºè¿«è¿›å…¥ | æ‰€æœ‰å˜é‡ä¸€æ¬¡æ€§çº³å…¥ | ç†è®ºé©±åŠ¨ç ”ç©¶ | å¯èƒ½åŒ…å«æ— å…³å˜é‡ |
| **Stepwise** | é€æ­¥å›å½’ | åŠ¨æ€è¿›é€€ï¼ŒåŒå‘ç­›é€‰ | æ¢ç´¢æ€§ç ”ç©¶ | ç»“æœä¸ç¨³å®šï¼Œè¿‡æ‹Ÿåˆ |
| **Forward** | å‘å‰é€‰æ‹© | é€ä¸ªæ·»åŠ æ˜¾è‘—å˜é‡ | å¿«é€Ÿç­›é€‰æ ¸å¿ƒå˜é‡ | æ˜“æ¼äº¤äº’é¡¹ |
| **Backward** | å‘åå‰”é™¤ | é€ä¸ªåˆ é™¤ä¸æ˜¾è‘—å˜é‡ | ä¿å®ˆç²¾ç®€ | å°æ ·æœ¬ä¸ç¨³å®š |
| **Remove** | å¼ºåˆ¶å‰”é™¤ | ä¸€æ¬¡æ€§åˆ é™¤æŒ‡å®šå˜é‡ | æ¨¡å‹å¯¹æ¯” | éœ€ç†è®ºæ”¯æ’‘ |
| **Hierarchical** | åˆ†å±‚/åˆ†å— | æŒ‰ç†è®ºåˆ†ç»„è¿›å…¥ | æ£€éªŒå¢é‡æ•ˆåº” | å—åºå½±å“ç»“è®º |

---

##### 1ï¸âƒ£ Enterï¼ˆå¼ºè¿«è¿›å…¥æ³•ï¼‰

##### åŸç†
å°†æ‰€æœ‰æŒ‡å®šçš„è‡ªå˜é‡**åŒæ—¶ã€å¼ºåˆ¶æ€§**çº³å…¥å›å½’æ¨¡å‹ï¼Œä¸è®ºå…¶ç»Ÿè®¡æ˜¾è‘—æ€§å¦‚ä½•ã€‚SPSSä¼šè®¡ç®—æ‰€æœ‰å˜é‡çš„å›å½’ç³»æ•°ï¼Œä½†ç ”ç©¶è€…éœ€è‡ªè¡Œåˆ¤æ–­å“ªäº›æœ‰æ„ä¹‰ã€‚

##### æ•°å­¦è¡¨è¾¾
$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_k X_k + \epsilon$$

æ‰€æœ‰ $\beta_i$ åŒæ—¶ä¼°è®¡ï¼Œå³ä½¿æŸäº› $p > 0.05$ã€‚

##### é€‚ç”¨åœºæ™¯
- âœ… **ç†è®ºé©±åŠ¨ç ”ç©¶**ï¼šæ–‡çŒ®å·²æ˜ç¡®å“ªäº›å˜é‡åº”çº³å…¥ï¼ˆå¦‚æ§åˆ¶å˜é‡ï¼‰
- âœ… **éªŒè¯æ€§åˆ†æ**ï¼šæ£€éªŒé¢„è®¾å‡è®¾ï¼Œè€Œéæ¢ç´¢æ–°å…³ç³»
- âœ… **éœ€è¦ä¿ç•™æ‰€æœ‰å˜é‡**ï¼šå³ä½¿ä¸æ˜¾è‘—ä¹Ÿæœ‰ç†è®ºæ„ä¹‰ï¼ˆå¦‚äººå£å­¦å˜é‡ï¼‰
- âœ… **æ— ä¸¥é‡å¤šé‡å…±çº¿æ€§**ï¼šVIF < 10

##### SPSSæ“ä½œ
```
Method: Enter
â†’ å°†æ‰€æœ‰å˜é‡ä¸€æ¬¡æ€§æ”¾å…¥ Independent(s)
```

##### ç¤ºä¾‹è¾“å‡ºè§£è¯»
```
Model Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Model    R      RÂ²     Adjusted RÂ²    Std. Error
1       .847   .718      .705          4.521
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Coefficients
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                 B      Std.Error    Beta      t       Sig.    VIF
(Constant)    -15.234    4.521               -3.37    .001
edu_years       2.156     .312      .298      6.91    .000    1.82
experience      1.423     .198      .341      7.19    .000    2.15
gender          3.245    1.024      .112      3.17    .002    1.12
performance     2.876     .456      .267      6.31    .000    1.34
age             -.234     .187     -.062     -1.25    .213    2.89  â† ä¸æ˜¾è‘—ä½†ä¿ç•™
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

#### âš ï¸ é€‰é”™åæœ
- **é—®é¢˜**ï¼šå¦‚æœå˜é‡é—´å­˜åœ¨é«˜åº¦å…±çº¿æ€§ï¼ˆVIF > 10ï¼‰ï¼Œç³»æ•°ä¼°è®¡ä¸ç¨³å®šï¼Œæ ‡å‡†è¯¯è†¨èƒ€
- **åæœ**ï¼šæœ¬åº”æ˜¾è‘—çš„å˜é‡å˜å¾—ä¸æ˜¾è‘—ï¼ˆType II Errorå¢åŠ ï¼‰
- **è¡¥æ•‘**ï¼šæ£€æŸ¥VIFï¼Œè€ƒè™‘åˆ é™¤æˆ–åˆå¹¶å…±çº¿æ€§å˜é‡

---

### 2ï¸âƒ£ Stepwiseï¼ˆé€æ­¥å›å½’æ³•ï¼‰

#### åŸç†
ç»“åˆ**å‘å‰é€‰æ‹©**å’Œ**å‘åå‰”é™¤**ï¼Œåœ¨æ¯ä¸€æ­¥éƒ½é‡æ–°è¯„ä¼°æ‰€æœ‰å·²å…¥é€‰å’Œå€™é€‰å˜é‡ï¼š
1. ä»ç©ºæ¨¡å‹å¼€å§‹
2. åŠ å…¥å½“å‰æœ€æ˜¾è‘—çš„å˜é‡ï¼ˆp < p_inï¼Œé»˜è®¤0.05ï¼‰
3. æ£€æŸ¥å·²å…¥é€‰å˜é‡ï¼Œå‰”é™¤å˜å¾—ä¸æ˜¾è‘—çš„ï¼ˆp > p_outï¼Œé»˜è®¤0.10ï¼‰
4. é‡å¤ç›´åˆ°æ— å˜é‡å¯åŠ æˆ–å¯åˆ 

#### æ•°å­¦é€»è¾‘
æ¯æ­¥è®¡ç®— **åFæ£€éªŒ**ï¼š
$$F = \frac{(SS_{reg,new} - SS_{reg,old}) / 1}{MS_{residual}}$$

è‹¥ $p(F) < 0.05$ åˆ™çº³å…¥ï¼Œè‹¥ $p(F) > 0.10$ åˆ™å‰”é™¤ã€‚

#### é€‚ç”¨åœºæ™¯
- âœ… **æ¢ç´¢æ€§ç ”ç©¶**ï¼šä¸ç¡®å®šå“ªäº›å˜é‡é‡è¦
- âœ… **å˜é‡ä¼—å¤šéœ€ç²¾ç®€**ï¼šä»20ä¸ªå˜é‡ä¸­ç­›é€‰5ä¸ªæ ¸å¿ƒå˜é‡
- âœ… **é¢„æµ‹å»ºæ¨¡**ï¼šè¿½æ±‚æ¨¡å‹ç®€æ´æ€§å’Œé¢„æµ‹åŠ›
- âŒ **ä¸é€‚åˆç†è®ºéªŒè¯**ï¼šç»“æœå—æ ·æœ¬æ³¢åŠ¨å½±å“å¤§

#### SPSSæ“ä½œ
```
Method: Stepwise
Options â†’ Stepping Method Criteria:
    Entry: .05
    Removal: .10
```

#### ç¤ºä¾‹è¾“å‡º
```
Variables Entered/Removed
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Step  Variable        Action     Sig.
1     experience      Entered    .000
2     edu_years       Entered    .000
3     performance     Entered    .000
4     gender          Entered    .004
5     age             Removed    .156  â† è¿›å…¥ååˆè¢«å‰”é™¤
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Final Model: salary = f(experience, edu_years, performance, gender)
```

#### âš ï¸ é€‰é”™åæœ

| é—®é¢˜ | åæœ | ä¸¥é‡ç¨‹åº¦ |
|------|------|----------|
| **è¿‡æ‹Ÿåˆ** | æ¨¡å‹åœ¨è®­ç»ƒé›†è¡¨ç°å¥½ï¼Œæ–°æ•°æ®ä¸Šå¤±æ•ˆ | â­â­â­ |
| **ç»“æœä¸ç¨³å®š** | æ¢ä¸ªæ ·æœ¬ï¼Œé€‰å‡ºçš„å˜é‡å®Œå…¨ä¸åŒ | â­â­â­ |
| **på€¼è†¨èƒ€** | å¤šé‡æ¯”è¾ƒå¯¼è‡´å‡é˜³æ€§å¢åŠ  | â­â­ |
| **å¿½ç•¥æŠ‘åˆ¶å˜é‡** | å•ç‹¬ä¸æ˜¾è‘—ä½†ç»„åˆåé‡è¦çš„å˜é‡è¢«æ¼æ‰ | â­â­ |
| **ç†è®ºè„±èŠ‚** | é€‰å‡ºçš„å˜é‡å¯èƒ½æ— æ³•è§£é‡Š | â­â­ |

**ç»å…¸åé¢æ¡ˆä¾‹**ï¼š
> æŸç ”ç©¶ç”¨Stepwiseåˆ†æå­¦ç”Ÿæˆç»©å½±å“å› ç´ ï¼Œç»“æœ"é‹ç "è¢«é€‰å…¥æ¨¡å‹ï¼ˆp=0.03ï¼‰ã€‚å®é™…ä¸Šé‹ç ä¸å¹´é¾„ç›¸å…³ï¼Œå¹´é¾„ä¸æˆç»©ç›¸å…³ï¼Œé‹ç åªæ˜¯è™šå‡ç›¸å…³(spurious correlation)ã€‚

---

### 3ï¸âƒ£ Forwardï¼ˆå‘å‰é€‰æ‹©æ³•ï¼‰

#### åŸç†
ä»**ç©ºæ¨¡å‹**ï¼ˆåªæœ‰æˆªè·ï¼‰å¼€å§‹ï¼Œæ¯æ¬¡åŠ å…¥ä¸€ä¸ªå½“å‰æœ€æ˜¾è‘—çš„å˜é‡ï¼Œç›´åˆ°æ²¡æœ‰å˜é‡æ»¡è¶³è¿›å…¥æ ‡å‡†ã€‚

```
Step 0: Y = Î²â‚€
Step 1: Y = Î²â‚€ + Î²â‚Xâ‚ (Xâ‚æ˜¯æœ€æ˜¾è‘—çš„)
Step 2: Y = Î²â‚€ + Î²â‚Xâ‚ + Î²â‚‚Xâ‚‚ (Xâ‚‚æ˜¯å‰©ä½™ä¸­æœ€æ˜¾è‘—çš„)
...
Stop: æ²¡æœ‰å‰©ä½™å˜é‡çš„ p < 0.05
```

#### ä¸Stepwiseçš„åŒºåˆ«
- Forwardï¼šåªè¿›ä¸å‡ºï¼ˆå˜é‡ä¸€æ—¦è¿›å…¥ä¸ä¼šè¢«å‰”é™¤ï¼‰
- Stepwiseï¼šå¯è¿›å¯å‡ºï¼ˆéšæ—¶æ£€æŸ¥å·²å…¥é€‰å˜é‡ï¼‰

#### é€‚ç”¨åœºæ™¯
- âœ… **å˜é‡å¾ˆå¤šï¼ˆ>15ä¸ªï¼‰**ï¼Œéœ€è¦å¿«é€Ÿç­›é€‰
- âœ… **æ ·æœ¬é‡ç›¸å¯¹è¾ƒå°**ï¼Œæ— æ³•æ”¯æ’‘å…¨æ¨¡å‹
- âœ… **åˆæ­¥æ¢ç´¢**ï¼Œæ‰¾å‡ºæœ€æ ¸å¿ƒçš„å‡ ä¸ªé¢„æµ‹å› å­
- âŒ **å˜é‡é—´æœ‰äº¤äº’æ•ˆåº”**æ—¶å®¹æ˜“é—æ¼

#### âš ï¸ é€‰é”™åæœ
- **é—æ¼æŠ‘åˆ¶å˜é‡**ï¼šå˜é‡Aå•ç‹¬ä¸Yæ— å…³ï¼Œä½†æ§åˆ¶BåAæ˜¾è‘—â€”â€”Forwardä¼šé”™è¿‡A
- **å±€éƒ¨æœ€ä¼˜**ï¼šç¬¬ä¸€ä¸ªè¿›å…¥çš„å˜é‡å¯èƒ½ä¸æ˜¯çœŸæ­£æœ€é‡è¦çš„
- **é¡ºåºä¾èµ–**ï¼šå¦‚æœä¸¤ä¸ªå˜é‡é«˜åº¦ç›¸å…³ï¼Œå…ˆè¿›å…¥çš„"éœ¸å "äº†è§£é‡ŠåŠ›

---

### 4ï¸âƒ£ Backwardï¼ˆå‘åå‰”é™¤æ³•ï¼‰

#### åŸç†
ä»**å…¨æ¨¡å‹**ï¼ˆåŒ…å«æ‰€æœ‰å˜é‡ï¼‰å¼€å§‹ï¼Œæ¯æ¬¡å‰”é™¤ä¸€ä¸ªæœ€ä¸æ˜¾è‘—çš„å˜é‡ï¼Œç›´åˆ°æ‰€æœ‰ä¿ç•™å˜é‡éƒ½æ˜¾è‘—ã€‚

```
Step 0: Y = Î²â‚€ + Î²â‚Xâ‚ + Î²â‚‚Xâ‚‚ + ... + Î²â‚–Xâ‚– (å…¨éƒ¨å˜é‡)
Step 1: å‰”é™¤ p å€¼æœ€å¤§ä¸” > 0.10 çš„å˜é‡
Step 2: é‡æ–°æ‹Ÿåˆï¼Œå†å‰”é™¤æœ€ä¸æ˜¾è‘—çš„
...
Stop: æ‰€æœ‰å˜é‡çš„ p < 0.10
```

#### é€‚ç”¨åœºæ™¯
- âœ… **ç†è®ºä¸Šåº”åŒ…å«è¾ƒå¤šå˜é‡**ï¼Œä½†éœ€è¦ç»Ÿè®¡ç²¾ç®€
- âœ… **æƒ³å…ˆçœ‹å…¨æ•ˆåº”**ï¼Œå†é€æ­¥ç®€åŒ–
- âœ… **æ ·æœ¬é‡å……è¶³**ï¼ˆè‡³å°‘ N > 10kï¼Œkä¸ºå˜é‡æ•°ï¼‰
- âŒ **æ ·æœ¬å°æ—¶éå¸¸ä¸ç¨³å®š**

#### ä¸Forwardçš„æ¯”è¾ƒ

| ç‰¹æ€§ | Forward | Backward |
|------|---------|----------|
| èµ·ç‚¹ | ç©ºæ¨¡å‹ | å…¨æ¨¡å‹ |
| å€¾å‘ | ä¿å®ˆï¼ˆå˜é‡å°‘ï¼‰ | æ¿€è¿›ï¼ˆå˜é‡å¤šï¼‰ |
| æŠ‘åˆ¶å˜é‡ | å®¹æ˜“é—æ¼ | è¾ƒå¥½ä¿ç•™ |
| è®¡ç®—é‡ | å° | å¤§ |
| ç¨³å®šæ€§ | è¾ƒç¨³å®š | æ ·æœ¬æ•æ„Ÿ |

#### âš ï¸ é€‰é”™åæœ
- **å°æ ·æœ¬ç¾éš¾**ï¼šå˜é‡æ•°æ¥è¿‘æ ·æœ¬æ•°æ—¶ï¼Œåˆå§‹å…¨æ¨¡å‹å·²ç»è¿‡æ‹Ÿåˆ
- **å…±çº¿æ€§æ”¾å¤§**ï¼šå…¨æ¨¡å‹ä¸­å…±çº¿æ€§é—®é¢˜æœ€ä¸¥é‡ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯å‰”é™¤
- **æ—©æœŸé”™è¯¯ä¼ æ’­**ï¼šå¦‚æœç¬¬ä¸€æ­¥å‰”é™¤äº†é‡è¦å˜é‡ï¼Œåç»­æ— æ³•æŒ½å›

---

### 5ï¸âƒ£ Removeï¼ˆå¼ºåˆ¶å‰”é™¤æ³•ï¼‰

#### åŸç†
**ä¸€æ¬¡æ€§ç§»é™¤**ç ”ç©¶è€…æŒ‡å®šçš„ä¸€ä¸ªæˆ–ä¸€ç»„å˜é‡ï¼Œç”¨äºå¯¹æ¯”å‰”é™¤å‰åæ¨¡å‹çš„å˜åŒ–ã€‚

#### é€‚ç”¨åœºæ™¯
- âœ… **åˆ†å—åˆ†æ**ï¼šå…ˆçº³å…¥æ§åˆ¶å˜é‡ï¼Œå†çœ‹å®éªŒå˜é‡çš„å¢é‡
- âœ… **æ¨¡å‹å¯¹æ¯”**ï¼šæ¯”è¾ƒæœ‰/æ— æŸå˜é‡æ—¶çš„RÂ²å˜åŒ–
- âœ… **ç†è®ºæ£€éªŒ**ï¼šéªŒè¯æŸå˜é‡æ˜¯å¦çœŸçš„ä¸é‡è¦

#### SPSSæ“ä½œ
```
Block 1: Method = Enter, Variables = [æ§åˆ¶å˜é‡]
Block 2: Method = Remove, Variables = [è¦å‰”é™¤çš„å˜é‡]
```

#### ç¤ºä¾‹ï¼šæ£€éªŒ"æ€§åˆ«"æ˜¯å¦æœ‰å¢é‡è´¡çŒ®
```
Model 1 (å«gender):    RÂ² = .718
Model 2 (å‰”é™¤gender):  RÂ² = .692
Î”RÂ² = .026, F(1,194) = 10.12, p = .002

ç»“è®ºï¼šæ€§åˆ«æœ‰æ˜¾è‘—çš„ç‹¬ç«‹è´¡çŒ®ï¼Œè§£é‡Šäº†2.6%çš„é¢å¤–æ–¹å·®
```

---

### 6ï¸âƒ£ Hierarchicalï¼ˆåˆ†å±‚/åˆ†å—å›å½’ï¼‰

#### åŸç†
å°†å˜é‡æŒ‰**ç†è®ºæ„ä¹‰**åˆ†æˆè‹¥å¹²"å—"(Block)ï¼ŒæŒ‰é¡ºåºä¾æ¬¡è¿›å…¥æ¨¡å‹ï¼Œæ£€éªŒæ¯ä¸€å—çš„**å¢é‡è§£é‡ŠåŠ›** (Î”RÂ²)ã€‚

```
Block 1: äººå£å­¦å˜é‡ (age, gender) â†’ RÂ²â‚
Block 2: æ•™è‚²èƒŒæ™¯ (edu_years) â†’ RÂ²â‚‚, Î”RÂ² = RÂ²â‚‚ - RÂ²â‚
Block 3: å·¥ä½œå› ç´  (experience, performance) â†’ RÂ²â‚ƒ, Î”RÂ² = RÂ²â‚ƒ - RÂ²â‚‚
```

#### æ ¸å¿ƒä»·å€¼
å›ç­”ï¼š"**åœ¨æ§åˆ¶äº†Aç±»å˜é‡åï¼ŒBç±»å˜é‡æ˜¯å¦è¿˜èƒ½æ˜¾è‘—æå‡é¢„æµ‹åŠ›ï¼Ÿ**"

#### é€‚ç”¨åœºæ™¯
- âœ… **æ£€éªŒå¢é‡æ•ˆåº”**ï¼šæ–°å˜é‡åœ¨æ§åˆ¶æ—§å˜é‡åæ˜¯å¦ä»æœ‰è´¡çŒ®
- âœ… **ç†è®ºåˆ†å±‚æ˜ç¡®**ï¼šå¦‚"å…ˆæ§åˆ¶äººå£å­¦ï¼Œå†çœ‹å¿ƒç†å˜é‡"
- âœ… **ä¸­ä»‹/è°ƒèŠ‚åˆ†æå‰å¥**ï¼šä¸ºåç»­åˆ†æå»ºç«‹åŸºç¡€æ¨¡å‹
- âœ… **ç¤¾ç§‘ç ”ç©¶æ ‡é…**ï¼šå‡ ä¹æ‰€æœ‰SCIç¤¾ç§‘è®ºæ–‡éƒ½ç”¨

#### SPSSæ“ä½œ
```
Block 1 of 3:
    Method: Enter
    Variables: age, gender
    [ç‚¹å‡» Next]

Block 2 of 3:
    Method: Enter
    Variables: edu_years
    [ç‚¹å‡» Next]

Block 3 of 3:
    Method: Enter
    Variables: experience, performance

Statistics â†’ å‹¾é€‰ "R squared change"
```

#### ç¤ºä¾‹è¾“å‡º
```
Model Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Model   R      RÂ²     Î”RÂ²     Î”F       df1   df2    Sig. Î”F
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1      .312   .097    .097    10.56     2    197    .000    â† äººå£å­¦
2      .534   .285    .188    51.23     1    196    .000    â† +æ•™è‚²
3      .847   .718    .433    148.67    2    194    .000    â† +å·¥ä½œå› ç´ 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

è§£è¯»ï¼š
- äººå£å­¦å˜é‡è§£é‡Šäº†9.7%çš„æ–¹å·®
- æ•™è‚²å¹´é™é¢å¤–è§£é‡Šäº†18.8%ï¼ˆæ§åˆ¶äººå£å­¦åï¼‰
- å·¥ä½œå› ç´ é¢å¤–è§£é‡Šäº†43.3%ï¼ˆæ§åˆ¶å‰ä¸¤è€…åï¼‰
- å·¥ä½œå› ç´ çš„å¢é‡è´¡çŒ®æœ€å¤§
```

#### âš ï¸ é€‰é”™åæœ
- **å—é¡ºåºå½±å“ç»“è®º**ï¼šå…ˆè¿›å…¥çš„å—ä¼š"æŠ¢å¤º"å…±äº«æ–¹å·®
  - ä¾‹ï¼šå…ˆæ”¾æ•™è‚²å†æ”¾æ™ºå•† vs å…ˆæ”¾æ™ºå•†å†æ”¾æ•™è‚²ï¼ŒÎ”RÂ²å¯èƒ½å®Œå…¨ä¸åŒ
- **ç†è®ºä¾æ®ç¼ºå¤±**ï¼šæ²¡æœ‰ç†è®ºæ”¯æ’‘çš„åˆ†å—é¡ºåºä¼šè¢«å®¡ç¨¿äººè´¨ç–‘
- **è¿‡åº¦åˆ†å—**ï¼šå—å¤ªå¤šä¼šå¢åŠ å¤šé‡æ¯”è¾ƒé—®é¢˜

---

## ğŸ§­ æ–¹æ³•é€‰æ‹©å†³ç­–æ ‘

```
                        ä½ çš„ç ”ç©¶ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿ
                              â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼                 â–¼                 â–¼
       éªŒè¯ç†è®ºå‡è®¾      æ¢ç´¢æ€§åˆ†æ        æ£€éªŒå¢é‡æ•ˆåº”
            â”‚                 â”‚                 â”‚
            â–¼                 â–¼                 â–¼
    å˜é‡æœ‰ç†è®ºä¾æ®ï¼Ÿ    å˜é‡æ•°é‡å¾ˆå¤šï¼Ÿ    å˜é‡å¯åˆ†ç»„ï¼Ÿ
      â”‚      â”‚           â”‚      â”‚          â”‚     â”‚
     æ˜¯     å¦          æ˜¯     å¦         æ˜¯    å¦
      â”‚      â”‚           â”‚      â”‚          â”‚     â”‚
      â–¼      â–¼           â–¼      â–¼          â–¼     â–¼
   Enter  Hierarchical Stepwise Enter  Hierarchical Enter
                        /Forward
```

### å¿«é€Ÿé€‰æ‹©æŒ‡å—

| ä½ çš„æƒ…å†µ | æ¨èæ–¹æ³• | åŸå›  |
|----------|----------|------|
| æ–‡çŒ®æ˜ç¡®å‘Šè¯‰ä½ è¦æ”¾å“ªäº›å˜é‡ | **Enter** | ç†è®ºé©±åŠ¨ï¼Œä¿ç•™æ‰€æœ‰å˜é‡ |
| ä¸çŸ¥é“å“ªäº›å˜é‡é‡è¦ï¼Œæƒ³æ¢ç´¢ | **Stepwise** | è‡ªåŠ¨ç­›é€‰ï¼Œä½†éœ€äº¤å‰éªŒè¯ |
| å˜é‡å¤ªå¤šï¼ˆ>20ä¸ªï¼‰ï¼Œå…ˆç²—ç­› | **Forward** | å¿«é€Ÿæ‰¾æ ¸å¿ƒå˜é‡ |
| æƒ³çœ‹å…¨æ•ˆåº”ï¼Œå†ç²¾ç®€ | **Backward** | ä¿å®ˆå‰”é™¤ |
| æƒ³æ¯”è¾ƒæœ‰/æ— æŸå˜é‡çš„å·®å¼‚ | **Remove** | æ¨¡å‹å¯¹æ¯” |
| æƒ³æ£€éªŒ"æ§åˆ¶Xåï¼ŒYæ˜¯å¦ä»æ˜¾è‘—" | **Hierarchical** | å¢é‡æ•ˆåº”æ£€éªŒ |
| SCIè®ºæ–‡ã€æ¯•ä¸šè®ºæ–‡ | **Hierarchical + Enter** | å­¦æœ¯æ ‡å‡†åšæ³• |

---

## âš ï¸ å¸¸è§é”™è¯¯ä¸åæœæ±‡æ€»

### é”™è¯¯1ï¼šæ¢ç´¢æ€§ç ”ç©¶ç”¨Enter

**åœºæ™¯**ï¼šæœ‰30ä¸ªå€™é€‰å˜é‡ï¼Œä¸çŸ¥é“å“ªäº›é‡è¦ï¼Œç›´æ¥å…¨éƒ¨Enter

**åæœ**ï¼š
- å¤šé‡å…±çº¿æ€§ä¸¥é‡ï¼ˆVIFçˆ†è¡¨ï¼‰
- ç³»æ•°ç¬¦å·å¯èƒ½ä¸é¢„æœŸç›¸å
- è¿‡æ‹Ÿåˆï¼Œæ¢ä¸ªæ ·æœ¬ç»“æœå®Œå…¨ä¸åŒ

**æ­£ç¡®åšæ³•**ï¼šå…ˆç”¨Stepwise/Forwardç­›é€‰ï¼Œå†ç”¨EnteréªŒè¯

---

### é”™è¯¯2ï¼šéªŒè¯æ€§ç ”ç©¶ç”¨Stepwise

**åœºæ™¯**ï¼šç†è®ºå‡è®¾"æ•™è‚²â†’è–ªèµ„"ï¼Œå´ç”¨Stepwiseè®©æ•°æ®å†³å®š

**åæœ**ï¼š
- æ•™è‚²å¯èƒ½å› ä¸ç»éªŒå…±çº¿è€Œè¢«å‰”é™¤
- å®¡ç¨¿äººè´¨ç–‘ï¼š"ä½ çš„å‡è®¾åœ¨å“ªé‡Œï¼Ÿ"
- ç»“æœä¸å¯å¤ç°

**æ­£ç¡®åšæ³•**ï¼šç”¨Enteræˆ–Hierarchicalä¿ç•™ç†è®ºå˜é‡

---

### é”™è¯¯3ï¼šHierarchicalå—é¡ºåºéšæ„

**åœºæ™¯**ï¼šå…ˆæ”¾"å·¥ä½œç»éªŒ"å†æ”¾"å¹´é¾„"

**åæœ**ï¼š
- ç»éªŒå’Œå¹´é¾„é«˜åº¦ç›¸å…³ï¼Œå…ˆè¿›å…¥çš„æŠ¢èµ°æ–¹å·®
- å¹´é¾„çš„Î”RÂ²æ¥è¿‘0ï¼Œè¢«è¯¯åˆ¤ä¸º"ä¸é‡è¦"
- å®é™…ä¸Šå¦‚æœåè¿‡æ¥æ”¾ï¼Œç»“è®ºå¯èƒ½å®Œå…¨ä¸åŒ

**æ­£ç¡®åšæ³•**ï¼š
1. éµå¾ªç†è®ºé€»è¾‘ï¼ˆå¦‚ï¼šå…ˆæ§åˆ¶å˜é‡ï¼Œå†è‡ªå˜é‡ï¼‰
2. æŠ¥å‘Šæ›¿ä»£é¡ºåºçš„ç»“æœä½œä¸ºç¨³å¥æ€§æ£€éªŒ

---

### é”™è¯¯4ï¼šå°æ ·æœ¬ç”¨Backward

**åœºæ™¯**ï¼šN=50ï¼Œå˜é‡æ•°k=15ï¼Œç”¨Backward

**åæœ**ï¼š
- åˆå§‹å…¨æ¨¡å‹å·²ç»ä¸¥é‡è¿‡æ‹Ÿåˆ
- å‰”é™¤è¿‡ç¨‹æä¸ç¨³å®š
- å¯èƒ½åˆ æ‰çœŸæ­£é‡è¦çš„å˜é‡

**æ­£ç¡®åšæ³•**ï¼šæ ·æœ¬é‡è§„åˆ™ï¼šN > 50 + 8kï¼ˆå³è‡³å°‘170ä¸ªæ ·æœ¬æ‰èƒ½ç”¨15ä¸ªå˜é‡ï¼‰

---

### é”™è¯¯5ï¼šåªæŠ¥å‘Šæœ€ç»ˆæ¨¡å‹

**åœºæ™¯**ï¼šç”¨Stepwiseï¼ŒåªæŠ¥å‘Šæœ€åé€‰å‡ºçš„å˜é‡

**åæœ**ï¼š
- è¯»è€…ä¸çŸ¥é“æœ‰å¤šå°‘å˜é‡è¢«ç­›æ‰
- æ— æ³•è¯„ä¼°ç»“æœç¨³å®šæ€§
- å¯å¤ç°æ€§å·®

**æ­£ç¡®åšæ³•**ï¼šæŠ¥å‘Šæ‰€æœ‰æ­¥éª¤ã€è¿›å…¥/å‰”é™¤çš„å˜é‡åŠå…¶på€¼

---

## ğŸ“Š å¸¸è§çš„æŠ¥å‘Šæ–¹æ³•

### æ–¹æ³•éƒ¨åˆ†å†™æ³•

> æœ¬ç ”ç©¶é‡‡ç”¨åˆ†å±‚å¤šå…ƒå›å½’åˆ†ææ£€éªŒå„å› ç´ å¯¹å‘˜å·¥è–ªèµ„çš„å½±å“ã€‚ç¬¬ä¸€å±‚çº³å…¥äººå£å­¦å˜é‡ï¼ˆå¹´é¾„ã€æ€§åˆ«ï¼‰ä½œä¸ºæ§åˆ¶å˜é‡ï¼›ç¬¬äºŒå±‚çº³å…¥æ•™è‚²èƒŒæ™¯ï¼ˆå—æ•™è‚²å¹´é™ï¼‰ï¼›ç¬¬ä¸‰å±‚çº³å…¥å·¥ä½œç›¸å…³å› ç´ ï¼ˆå·¥ä½œç»éªŒã€ç»©æ•ˆè¯„åˆ†ï¼‰ã€‚å„å±‚å‡é‡‡ç”¨å¼ºè¿«è¿›å…¥æ³•(Enter)ã€‚é‡‡ç”¨æ–¹å·®è†¨èƒ€å› å­(VIF)è¯Šæ–­å¤šé‡å…±çº¿æ€§ï¼Œä»¥VIF < 10ä¸ºå¯æ¥å—æ ‡å‡†ã€‚

### ç»“æœéƒ¨åˆ†å†™æ³•

> è¡¨Xå‘ˆç°äº†åˆ†å±‚å›å½’åˆ†æç»“æœã€‚æ¨¡å‹1ä¸­ï¼Œäººå£å­¦å˜é‡è§£é‡Šäº†è–ªèµ„9.7%çš„æ–¹å·®ï¼ˆF(2,197)=10.56, p<.001ï¼‰ã€‚åŠ å…¥æ•™è‚²å¹´é™åï¼Œæ¨¡å‹è§£é‡ŠåŠ›æ˜¾è‘—æå‡ï¼ˆÎ”RÂ²=.188, Î”F(1,196)=51.23, p<.001ï¼‰ï¼Œè¡¨æ˜æ•™è‚²å¯¹è–ªèµ„æœ‰ç‹¬ç«‹è´¡çŒ®ã€‚æœ€ç»ˆæ¨¡å‹ä¸­ï¼Œå·¥ä½œå› ç´ çš„åŠ å…¥ä½¿è§£é‡ŠåŠ›è¿›ä¸€æ­¥æå‡è‡³71.8%ï¼ˆÎ”RÂ²=.433, Î”F(2,194)=148.67, p<.001ï¼‰ã€‚æœ€ç»ˆæ¨¡å‹ä¸­ï¼Œå·¥ä½œç»éªŒï¼ˆÎ²=.341, p<.001ï¼‰å’Œç»©æ•ˆè¯„åˆ†ï¼ˆÎ²=.267, p<.001ï¼‰æ˜¯è–ªèµ„çš„æœ€å¼ºé¢„æµ‹å› å­ã€‚æ‰€æœ‰VIFå€¼å‡å°äº3ï¼Œä¸å­˜åœ¨ä¸¥é‡å…±çº¿æ€§é—®é¢˜ã€‚

---

## ğŸ“š ç›¸å…³åè¯

1. **å¤šé‡å…±çº¿æ€§è¯Šæ–­**ï¼šVIFã€æ¡ä»¶æŒ‡æ•°ã€æ–¹å·®æ¯”ä¾‹
2. **æ®‹å·®è¯Šæ–­**ï¼šæ­£æ€æ€§ã€åŒæ–¹å·®æ€§ã€ç‹¬ç«‹æ€§
3. **äº¤å‰éªŒè¯**ï¼šè¯„ä¼°Stepwiseç»“æœçš„ç¨³å®šæ€§
4. **æ­£åˆ™åŒ–å›å½’**ï¼šRidgeã€Lassoï¼ˆè§£å†³å…±çº¿æ€§çš„ç°ä»£æ–¹æ³•ï¼‰

---

## 9. ç§‘ç ”ç»˜å›¾ï¼šOriginLab

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜                                   |
|------|--------------------------------------|
| **ç”¨é€”** | ç§‘ç ”ç»˜å›¾ã€å‡ºç‰ˆçº§å›¾è¡¨ï¼Œbutä¹Ÿå¯ä»¥åšä¸€äº›å›å½’åˆ†æï¼Œå…·ä½“æˆ‘æ²¡æ€ä¹ˆç”¨è¿‡orz |
| **è´¹ç”¨** | ğŸ’° ä»˜è´¹ï¼ˆå®éªŒå®¤é€šå¸¸æœ‰æˆæƒï¼‰                      |
| **å®˜ç½‘** | https://www.originlab.com            |

### ğŸ“ ä½¿ç”¨æŠ€å·§
1. **å¯¼å…¥æ•°æ®**ï¼šç›´æ¥ä»Excelç²˜è´´æˆ–File â†’ Import
2. **åˆ›å»ºå›¾è¡¨**ï¼šé€‰ä¸­æ•°æ®åˆ— â†’ Plot â†’ é€‰æ‹©å›¾è¡¨ç±»å‹
3. **å¯¼å‡º**ï¼šFile â†’ Export Graphs â†’ é€‰æ‹©PDF/EPS/TIFF

---

## 10. åŠå…¬å¥—ä»¶ï¼šMicrosoft Office

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | æ–‡æ¡£å¤„ç†ã€æ•°æ®è¡¨æ ¼ã€æ¼”ç¤ºæ–‡ç¨¿ |
| **è´¹ç”¨** | ğŸ’° ä»˜è´¹ï¼ˆå­¦æ ¡.edué‚®ç®±é€šå¸¸å…è´¹ï¼‰ |
| **å®˜ç½‘** | https://www.office.com |

### ğŸ’¡ å°æŠ€å·§
> `.docx` å’Œ `.pptx` æ–‡ä»¶æœ¬è´¨ä¸Šæ˜¯å‹ç¼©åŒ…ã€‚å¦‚æœéœ€è¦æå–å…¶ä¸­çš„å›¾ç‰‡ï¼Œå¯ä»¥å°†æ–‡ä»¶æ‰©å±•åæ”¹ä¸º `.zip`ï¼Œç„¶åè§£å‹ï¼Œå›¾ç‰‡åœ¨ `word/media/` æˆ– `ppt/media/` æ–‡ä»¶å¤¹ä¸­ã€‚

---

## 11. å›¾åƒå¤„ç†ï¼šAdobeç³»åˆ—

### ğŸ“Œ ç®€ä»‹
| è½¯ä»¶ | ç”¨é€” | è´¹ç”¨ |
|------|------|------|
| **Acrobat** | PDFç¼–è¾‘ | ğŸ’° è®¢é˜…åˆ¶ |
| **Illustrator** | çŸ¢é‡å›¾ç¼–è¾‘ | ğŸ’° è®¢é˜…åˆ¶ |
| **Photoshop** | ä½å›¾ç¼–è¾‘ | ğŸ’° è®¢é˜…åˆ¶ |

### ğŸ“ å­¦æœ¯ç»‘å›¾å·¥ä½œæµ

```
Python/MATLABç”Ÿæˆå›¾ â†’ å¯¼å‡ºSVG â†’ Illustratorç²¾ä¿® â†’ å¯¼å‡ºPDF â†’ æ’å…¥è®ºæ–‡
```

**ä¸ºä»€ä¹ˆç”¨SVGï¼Ÿ**
- çŸ¢é‡æ ¼å¼ï¼Œæ— é™æ”¾å¤§ä¸å¤±çœŸ
- æ–‡ä»¶ä½“ç§¯å°
- å¯åœ¨Illustratorä¸­ç¼–è¾‘æ¯ä¸ªå…ƒç´ 

---

## 12. å­¦æœ¯å†™ä½œï¼šLaTeXä¸Overleaf

### ğŸ“Œ ç®€ä»‹
| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **ç”¨é€”** | å­¦æœ¯è®ºæ–‡æ’ç‰ˆï¼Œæ•°å­¦å…¬å¼ |
| **è´¹ç”¨** | âœ… å…è´¹ï¼ˆOverleafåŸºç¡€ç‰ˆï¼‰ |
| **å®˜ç½‘** | https://www.overleaf.com |

### ğŸ“ åŸºç¡€è¯­æ³•ç¤ºä¾‹

```latex
\documentclass{article}
\usepackage{amsmath}
\usepackage{graphicx}

\title{My Research Paper}
\author{Your Name}

\begin{document}
\maketitle

\section{Introduction}
This is my paper.

\section{Methods}
The Gaussian Process is defined as:
\begin{equation}
    f(x) \sim \mathcal{GP}(m(x), k(x, x'))
\end{equation}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figure.pdf}
    \caption{Results}
\end{figure}

\end{document}
```

---

## 13. è¿›é˜¶ï¼šæ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ

### ğŸ“Œ ä»€ä¹ˆæ˜¯å¯è§£é‡Šæ€§ï¼Ÿä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ

æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå°¤å…¶æ˜¯æ·±åº¦å­¦ä¹ ï¼‰å¸¸è¢«ç§°ä¸º**"é»‘ç®±"**â€”â€”æˆ‘ä»¬çŸ¥é“è¾“å…¥å’Œè¾“å‡ºï¼Œä½†ä¸çŸ¥é“å†…éƒ¨å†³ç­–è¿‡ç¨‹ã€‚

**å¯è§£é‡Šæ€§åˆ†æ**å¸®åŠ©æˆ‘ä»¬å›ç­”ï¼š
- æ¨¡å‹ä¾æ®ä»€ä¹ˆç‰¹å¾åšå‡ºé¢„æµ‹ï¼Ÿ
- å“ªäº›ç‰¹å¾æœ€é‡è¦ï¼Ÿ
- ç‰¹å¾å¦‚ä½•å½±å“é¢„æµ‹ç»“æœï¼ˆæ­£å‘/è´Ÿå‘ï¼‰ï¼Ÿ

**ä¸ºä»€ä¹ˆé‡è¦ï¼Ÿ**
1. **ç§‘å­¦å‘ç°**ï¼šç†è§£æ¨¡å‹å­¦åˆ°äº†ä»€ä¹ˆè§„å¾‹
2. **æ¨¡å‹è°ƒè¯•**ï¼šå‘ç°æ¨¡å‹æ˜¯å¦å­¦åˆ°äº†é”™è¯¯çš„æ¨¡å¼
3. **å»ºç«‹ä¿¡ä»»**ï¼šè®©ç”¨æˆ·ç†è§£å¹¶ä¿¡ä»»æ¨¡å‹
4. **ç›‘ç®¡åˆè§„**ï¼šæŸäº›é¢†åŸŸï¼ˆåŒ»ç–—ã€é‡‘èï¼‰è¦æ±‚æ¨¡å‹å¯è§£é‡Š

### ğŸ“Œ SHAPåŸç†è¯¦è§£

**SHAP (SHapley Additive exPlanations)** åŸºäºåšå¼ˆè®ºä¸­çš„**Shapleyå€¼**ï¼Œæ˜¯ç›®å‰æœ€æµè¡Œçš„å¯è§£é‡Šæ€§æ–¹æ³•ã€‚

#### æ ¸å¿ƒæ€æƒ³

å‡è®¾ä½ å’Œæœ‹å‹ä»¬ä¸€èµ·å®Œæˆäº†ä¸€ä¸ªé¡¹ç›®ï¼Œè·å¾—äº†100å…ƒå¥–é‡‘ã€‚å¦‚ä½•å…¬å¹³åœ°åˆ†é…è¿™100å…ƒï¼Ÿ

Shapleyå€¼çš„æ€æƒ³æ˜¯ï¼š**è®¡ç®—æ¯ä¸ªäººå¯¹é¡¹ç›®çš„è¾¹é™…è´¡çŒ®**ã€‚

å¯¹äºæœºå™¨å­¦ä¹ æ¨¡å‹ï¼š
- "é¡¹ç›®å¥–é‡‘" = æ¨¡å‹é¢„æµ‹å€¼
- "å‚ä¸è€…" = å„ä¸ªç‰¹å¾
- "è¾¹é™…è´¡çŒ®" = æŸç‰¹å¾å¯¹é¢„æµ‹çš„å½±å“

#### æ•°å­¦å®šä¹‰

å¯¹äºç‰¹å¾ $i$ï¼Œå…¶SHAPå€¼ä¸ºï¼š

$$\phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(|N|-|S|-1)!}{|N|!} [f(S \cup \{i\}) - f(S)]$$

å…¶ä¸­ï¼š
- $N$ æ˜¯æ‰€æœ‰ç‰¹å¾çš„é›†åˆ
- $S$ æ˜¯ä¸åŒ…å«ç‰¹å¾ $i$ çš„ç‰¹å¾å­é›†
- $f(S)$ æ˜¯åªç”¨ç‰¹å¾å­é›† $S$ æ—¶çš„æ¨¡å‹é¢„æµ‹

#### SHAPçš„ä¼˜è‰¯æ€§è´¨

1. **å±€éƒ¨å‡†ç¡®æ€§**ï¼šæ‰€æœ‰ç‰¹å¾çš„SHAPå€¼ä¹‹å’Œç­‰äºé¢„æµ‹å€¼ä¸åŸºå‡†å€¼ä¹‹å·®
   $$f(x) = \phi_0 + \sum_{i=1}^{n} \phi_i$$

2. **ç¼ºå¤±æ€§**ï¼šå¦‚æœæŸç‰¹å¾ä¸å½±å“é¢„æµ‹ï¼Œå…¶SHAPå€¼ä¸º0

3. **ä¸€è‡´æ€§**ï¼šå¦‚æœç‰¹å¾çš„è´¡çŒ®å¢åŠ ï¼Œå…¶SHAPå€¼ä¸ä¼šå‡å°‘

### ğŸ“ SHAPåˆ†æç¤ºä¾‹

![SHAPå¯è§£é‡Šæ€§åˆ†æ](shap_analysis.png)
*å›¾3ï¼šSHAPå¯è§£é‡Šæ€§åˆ†æå››è”å›¾*

**å›¾è¡¨è§£è¯»ï¼š**
- **å·¦ä¸Š (Feature Importance)**ï¼šç‰¹å¾é‡è¦æ€§æ’åï¼Œæ¡å½¢è¶Šé•¿è¶Šé‡è¦
- **å³ä¸Š (Summary Plot)**ï¼šæ¯ä¸ªç‚¹ä»£è¡¨ä¸€ä¸ªæ ·æœ¬ï¼Œé¢œè‰²è¡¨ç¤ºç‰¹å¾å€¼é«˜ä½ï¼Œæ¨ªè½´æ˜¯SHAPå€¼
- **å·¦ä¸‹ (Waterfall Plot)**ï¼šå•ä¸ªæ ·æœ¬çš„é¢„æµ‹åˆ†è§£ï¼Œçº¢è‰²å¢åŠ é¢„æµ‹ï¼Œè“è‰²é™ä½é¢„æµ‹
- **å³ä¸‹ (Dependence Plot)**ï¼šç‰¹å¾å€¼ä¸SHAPå€¼çš„å…³ç³»ï¼Œå±•ç¤ºéçº¿æ€§æ•ˆåº”

```python
"""
SHAPå¯è§£é‡Šæ€§åˆ†æç¤ºä¾‹
æ–‡ä»¶ï¼šshap_analysis.py
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor

np.random.seed(42)

# ============== 1. å‡†å¤‡å¤šç‰¹å¾æ•°æ® ==============
years = np.array([2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015,
                  2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023])
enrollment = np.array([128.2, 120, 124.6, 140.6, 151.1, 165.6, 176, 172,
                       164.9, 177, 201, 238, 290, 341, 377, 457, 474])

# ç‰¹å¾ï¼šå¹´ä»½ã€å‰ä¸€å¹´äººæ•°ã€å‰ä¸¤å¹´äººæ•°
prev_1 = np.array([127.1, 128.2, 120, 124.6, 140.6, 151.1, 165.6, 176, 172,
                   164.9, 177, 201, 238, 290, 341, 377, 457])
prev_2 = np.array([117.2, 127.1, 128.2, 120, 124.6, 140.6, 151.1, 165.6, 176,
                   172, 164.9, 177, 201, 238, 290, 341, 377])

X = np.column_stack([years, prev_1, prev_2])
y = enrollment
feature_names = ['Year', 'Prev_Year', 'Prev_2_Year']

# ============== 2. è®­ç»ƒæ¨¡å‹ ==============
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X, y)

# è·å–ç‰¹å¾é‡è¦æ€§
importances = model.feature_importances_

# ============== 3. è®¡ç®—è¿‘ä¼¼SHAPå€¼ ==============
# ç®€åŒ–ç‰ˆï¼šåŸºäºç‰¹å¾åç¦»å‡å€¼çš„è´¡çŒ®
n_samples = len(X)
shap_values = np.zeros_like(X, dtype=float)
for i in range(X.shape[1]):
    for j in range(n_samples):
        mean_val = X[:, i].mean()
        deviation = (X[j, i] - mean_val) / (X[:, i].std() + 1e-8)
        shap_values[j, i] = deviation * importances[i] * 50  # ç¼©æ”¾

# ============== 4. å¯è§†åŒ–ï¼ˆ2x2å››å­å›¾ï¼‰ ==============
fig, axes = plt.subplots(2, 2, figsize=(14, 11))
sorted_idx = np.argsort(importances)[::-1]

# å­å›¾1ï¼šç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
ax1 = axes[0, 0]
colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(feature_names)))
bars = ax1.barh(range(len(feature_names)), importances[sorted_idx], 
                color=colors, edgecolor='black', alpha=0.8)
ax1.set_yticks(range(len(feature_names)))
ax1.set_yticklabels([feature_names[i] for i in sorted_idx], fontsize=12)
ax1.set_xlabel('Feature Importance', fontsize=12)
ax1.set_title('Feature Importance (Random Forest)', fontsize=13, fontweight='bold')
ax1.invert_yaxis()
for bar, imp in zip(bars, importances[sorted_idx]):
    ax1.text(imp + 0.01, bar.get_y() + bar.get_height()/2, f'{imp:.3f}', va='center')

# å­å›¾2ï¼šSHAP Summary Plotï¼ˆèœ‚ç¾¤å›¾ï¼‰
ax2 = axes[0, 1]
for i, feat_idx in enumerate(sorted_idx):
    y_pos = np.ones(n_samples) * i + np.random.normal(0, 0.08, n_samples)
    colors_scatter = plt.cm.RdBu_r((X[:, feat_idx] - X[:, feat_idx].min()) / 
                                    (X[:, feat_idx].max() - X[:, feat_idx].min() + 1e-8))
    ax2.scatter(shap_values[:, feat_idx], y_pos, c=colors_scatter, alpha=0.6, s=50)
ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.5)
ax2.set_yticks(range(len(feature_names)))
ax2.set_yticklabels([feature_names[i] for i in sorted_idx], fontsize=12)
ax2.set_xlabel('SHAP Value (Impact on Prediction)', fontsize=12)
ax2.set_title('SHAP Summary Plot', fontsize=13, fontweight='bold')
ax2.invert_yaxis()
# é¢œè‰²æ¡
sm = plt.cm.ScalarMappable(cmap='RdBu_r', norm=plt.Normalize(0, 1))
cbar = plt.colorbar(sm, ax=ax2, shrink=0.5)
cbar.set_label('Feature Value (Low â†’ High)', fontsize=10)

# å­å›¾3ï¼šå•æ ·æœ¬Waterfallå›¾ï¼ˆ2023å¹´ï¼‰
ax3 = axes[1, 0]
sample_idx = len(X) - 1  # 2023å¹´
base_value = y.mean()
sample_shap = shap_values[sample_idx]
prediction = model.predict(X[[sample_idx]])[0]

cumsum = np.cumsum(sample_shap[sorted_idx])
starts = np.concatenate([[base_value], base_value + cumsum[:-1]])
widths = sample_shap[sorted_idx]
colors_bar = ['#e74c3c' if w > 0 else '#3498db' for w in widths]

for i, (start, width, color) in enumerate(zip(starts, widths, colors_bar)):
    ax3.barh(i, width, left=start, color=color, edgecolor='black', alpha=0.8, height=0.6)
    ax3.text(start + width/2, i, f'{width:+.1f}', ha='center', va='center', 
             fontsize=10, color='white', fontweight='bold')

ax3.axvline(x=base_value, color='gray', linestyle='--', label=f'Base: {base_value:.0f}')
ax3.axvline(x=prediction, color='red', linestyle='-', linewidth=2, label=f'Pred: {prediction:.0f}')
ax3.set_yticks(range(len(feature_names)))
ax3.set_yticklabels([feature_names[i] for i in sorted_idx], fontsize=12)
ax3.set_xlabel('Contribution to Prediction', fontsize=12)
ax3.set_title(f'Waterfall Plot for 2023 (True: {y[-1]:.0f})', fontsize=13, fontweight='bold')
ax3.legend(fontsize=10)
ax3.invert_yaxis()

# å­å›¾4ï¼šç‰¹å¾ä¾èµ–å›¾
ax4 = axes[1, 1]
feat_idx = 1  # Prev_Year
scatter = ax4.scatter(X[:, feat_idx], shap_values[:, feat_idx], 
                       c=y, cmap='viridis', s=80, edgecolors='black', alpha=0.8)
ax4.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
# è¶‹åŠ¿çº¿
z = np.polyfit(X[:, feat_idx], shap_values[:, feat_idx], 1)
p = np.poly1d(z)
x_line = np.linspace(X[:, feat_idx].min(), X[:, feat_idx].max(), 100)
ax4.plot(x_line, p(x_line), 'r--', linewidth=2, label='Trend')
ax4.set_xlabel(f'{feature_names[feat_idx]} (10k)', fontsize=12)
ax4.set_ylabel('SHAP Value', fontsize=12)
ax4.set_title(f'Dependence Plot: {feature_names[feat_idx]}', fontsize=13, fontweight='bold')
ax4.legend(fontsize=10)
cbar = plt.colorbar(scatter, ax=ax4, shrink=0.8)
cbar.set_label('Enrollment', fontsize=10)

plt.tight_layout()
plt.savefig('shap_analysis.png', dpi=300, bbox_inches='tight')
plt.savefig('shap_analysis.pdf', bbox_inches='tight')
plt.savefig('shap_analysis.svg', bbox_inches='tight')
plt.show()
```

### ğŸ“Š å…¶ä»–å¯è§£é‡Šæ€§æ–¹æ³•

| æ–¹æ³• | é€‚ç”¨æ¨¡å‹ | ç‰¹ç‚¹ |
|------|----------|------|
| **SHAP** | æ‰€æœ‰æ¨¡å‹ | åŸºäºåšå¼ˆè®ºï¼Œç†è®ºä¸¥è°¨ï¼Œå…¨å±€+å±€éƒ¨è§£é‡Š |
| **LIME** | æ‰€æœ‰æ¨¡å‹ | å±€éƒ¨çº¿æ€§è¿‘ä¼¼ï¼Œç›´è§‚æ˜“æ‡‚ |
| **Attention** | Transformer | å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡ |
| **Grad-CAM** | CNN | å¯è§†åŒ–å›¾åƒä¸­çš„é‡è¦åŒºåŸŸ |
| **Permutation** | æ‰€æœ‰æ¨¡å‹ | ç®€å•ç›´æ¥ï¼Œæ‰“ä¹±ç‰¹å¾çœ‹å½±å“ |

---

## 14. è¿›é˜¶ï¼šæ¶ˆèå®éªŒè®¾è®¡

### ğŸ“Œ ä»€ä¹ˆæ˜¯æ¶ˆèå®éªŒï¼Ÿ

**æ¶ˆèå®éªŒ (Ablation Study)** æºè‡ªç¥ç»ç§‘å­¦â€”â€”é€šè¿‡"åˆ‡é™¤"å¤§è„‘æŸä¸ªåŒºåŸŸæ¥ç ”ç©¶å…¶åŠŸèƒ½ã€‚

åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæ¶ˆèå®éªŒé€šè¿‡**ç³»ç»Ÿåœ°ç§»é™¤æˆ–ä¿®æ”¹æ¨¡å‹ç»„ä»¶**ï¼Œæ¥éªŒè¯æ¯ä¸ªç»„ä»¶çš„è´¡çŒ®ã€‚

### ğŸ“Œ ä¸ºä»€ä¹ˆè¦åšæ¶ˆèå®éªŒï¼Ÿ

1. **éªŒè¯æœ‰æ•ˆæ€§**ï¼šè¯æ˜ä½ æå‡ºçš„æ–¹æ³•ç¡®å®æœ‰ç”¨
2. **ç†è§£è´¡çŒ®**ï¼šé‡åŒ–æ¯ä¸ªç»„ä»¶çš„è´¡çŒ®å¤§å°
3. **å­¦æœ¯è¦æ±‚**ï¼šé¡¶ä¼šè®ºæ–‡çš„æ ‡å‡†è¦æ±‚
4. **æ¨¡å‹ç®€åŒ–**ï¼šæ‰¾å‡ºä¸å¿…è¦çš„ç»„ä»¶

### ğŸ“Œ æ¶ˆèå®éªŒçš„ç±»å‹

| ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **ç»„ä»¶æ¶ˆè** | ç§»é™¤æ¨¡å‹çš„æŸä¸ªç»„ä»¶ | ç§»é™¤Attentionå±‚ |
| **ç‰¹å¾æ¶ˆè** | ç§»é™¤æŸç±»ç‰¹å¾ | ä¸ä½¿ç”¨æ—¶é—´ç‰¹å¾ |
| **è¶…å‚æ•°æ¶ˆè** | æ”¹å˜è¶…å‚æ•° | ä¸åŒéšè—å±‚å¤§å° |
| **æ•°æ®æ¶ˆè** | æ”¹å˜è®­ç»ƒæ•°æ® | ä½¿ç”¨ä¸åŒæ¯”ä¾‹çš„æ•°æ® |

### ğŸ“ æ¶ˆèå®éªŒç¤ºä¾‹ï¼šå¤šæ¨¡å‹å¯¹æ¯”

![æ¶ˆèå®éªŒç»“æœ](ablation_study.png)
*å›¾4ï¼šæ¶ˆèå®éªŒ - å¤šæ¨¡å‹é¢„æµ‹æ•ˆæœå¯¹æ¯”*

**å›¾è¡¨è§£è¯»ï¼š**
- **å·¦ä¸Š**ï¼šå„æ¨¡å‹RMSEå¯¹æ¯”ï¼Œè¶Šä½è¶Šå¥½
- **å³ä¸Š**ï¼šå„æ¨¡å‹é¢„æµ‹æ›²çº¿ä¸çœŸå®å€¼å¯¹æ¯”
- **å·¦ä¸‹**ï¼šæœ€ä½³æ¨¡å‹çš„è¯¦ç»†æ‹Ÿåˆæ•ˆæœ
- **å³ä¸‹**ï¼šå®éªŒç»“è®ºæ€»ç»“

```python
"""
æ¶ˆèå®éªŒï¼šæ¯”è¾ƒå¤šç§æ¨¡å‹é¢„æµ‹è€ƒç ”äººæ•°
æ–‡ä»¶ï¼šablation_study.py

ç›®çš„ï¼šé€šè¿‡å¯¹æ¯”ä¸åŒæ¨¡å‹ï¼ŒéªŒè¯å“ªç§æ–¹æ³•æœ€é€‚åˆè¿™ä¸ªä»»åŠ¡
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, Matern, WhiteKernel
from sklearn.metrics import mean_squared_error, mean_absolute_error

# ============== 1. æ•°æ®å‡†å¤‡ ==============
train_years = np.array([2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,
                        2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023])
train_values = np.array([117.2, 127.1, 128.2, 120, 124.6, 140.6, 151.1, 165.6, 176, 172,
                         164.9, 177, 201, 238, 290, 341, 377, 457, 474])

test_years = np.array([2024, 2025, 2026])
test_values = np.array([438, 388, 343])

# æ ‡å‡†åŒ–
X_train = (train_years - 2005).reshape(-1, 1) / 20.0
X_test = (test_years - 2005).reshape(-1, 1) / 20.0
y_mean, y_std = train_values.mean(), train_values.std()
y_train_norm = (train_values - y_mean) / y_std

# ============== 2. å®šä¹‰å¹¶è®­ç»ƒå¤šä¸ªæ¨¡å‹ ==============
results = {}

# æ¨¡å‹1ï¼šçº¿æ€§å›å½’ï¼ˆBaselineï¼‰
lr = LinearRegression()
lr.fit(X_train, train_values)
results['Linear'] = lr.predict(X_test)

# æ¨¡å‹2ï¼šå¤šé¡¹å¼å›å½’ï¼ˆ2æ¬¡ï¼‰
poly2 = PolynomialFeatures(2)
X_tr_p2 = poly2.fit_transform(X_train)
X_te_p2 = poly2.transform(X_test)
lr2 = LinearRegression()
lr2.fit(X_tr_p2, train_values)
results['Poly-2'] = lr2.predict(X_te_p2)

# æ¨¡å‹3ï¼šSVR
svr = SVR(kernel='rbf', C=500, gamma=1.0, epsilon=10)
svr.fit(X_train, train_values)
results['SVR-RBF'] = svr.predict(X_test)

# æ¨¡å‹4ï¼šéšæœºæ£®æ—
rf = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)
rf.fit(X_train, train_values)
results['Random Forest'] = rf.predict(X_test)

# æ¨¡å‹5ï¼šæ¢¯åº¦æå‡
gb = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)
gb.fit(X_train, train_values)
results['Gradient Boost'] = gb.predict(X_test)

# æ¨¡å‹6ï¼šé«˜æ–¯è¿‡ç¨‹å›å½’
kernel = 1.0 * Matern(length_scale=0.5, nu=2.5) + WhiteKernel(noise_level=0.1)
gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=20, 
                                alpha=1e-2, random_state=42)
gpr.fit(X_train, y_train_norm)
y_pred_norm = gpr.predict(X_test)
results['GPR-Matern'] = y_pred_norm * y_std + y_mean

# ============== 3. è¯„ä¼°æ‰€æœ‰æ¨¡å‹ ==============
print("="*80)
print("æ¶ˆèå®éªŒï¼šæ¨¡å‹é¢„æµ‹å¯¹æ¯”")
print("="*80)
print(f"\nçœŸå®å€¼: 2024={test_values[0]}, 2025={test_values[1]}, 2026={test_values[2]}")
print("\n" + "-"*80)
print(f"{'æ¨¡å‹':<18}{'RMSE':<10}{'MAE':<10}{'2024':<10}{'2025':<10}{'2026':<10}{'è¶‹åŠ¿'}")
print("-"*80)

model_stats = []
for name, preds in results.items():
    rmse = np.sqrt(mean_squared_error(test_values, preds))
    mae = mean_absolute_error(test_values, preds)
    if preds[0] > preds[1] > preds[2]:
        trend = "â†“ä¸‹é™"
    elif preds[0] < preds[1] < preds[2]:
        trend = "â†‘ä¸Šå‡"
    else:
        trend = "ï½æ³¢åŠ¨"
    model_stats.append((name, rmse, mae, preds.copy(), trend))
    print(f"{name:<18}{rmse:<10.1f}{mae:<10.1f}{preds[0]:<10.1f}{preds[1]:<10.1f}{preds[2]:<10.1f}{trend}")

model_stats.sort(key=lambda x: x[1])  # æŒ‰RMSEæ’åº
print("-"*80)
print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {model_stats[0][0]} (RMSE={model_stats[0][1]:.1f})")

# ============== 4. å¯è§†åŒ–ï¼ˆ2x2å››å­å›¾ï¼‰ ==============
fig = plt.figure(figsize=(16, 12))

# å­å›¾1ï¼šRMSEå¯¹æ¯”æ¡å½¢å›¾
ax1 = fig.add_subplot(2, 2, 1)
names = [m[0] for m in model_stats]
rmses = [m[1] for m in model_stats]
colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(names)))

bars = ax1.barh(range(len(names)), rmses, color=colors, edgecolor='black', alpha=0.8)
ax1.set_yticks(range(len(names)))
ax1.set_yticklabels(names, fontsize=11)
ax1.set_xlabel('RMSE (10k persons)', fontsize=12)
ax1.set_title('Model Comparison by RMSE (Lower is Better)', fontsize=13, fontweight='bold')
ax1.invert_yaxis()
for bar, rmse in zip(bars, rmses):
    ax1.text(rmse + 2, bar.get_y() + bar.get_height()/2, f'{rmse:.1f}', va='center', fontsize=10)
ax1.axvline(x=min(rmses), color='green', linestyle='--', alpha=0.5)

# å­å›¾2ï¼šæ‰€æœ‰æ¨¡å‹é¢„æµ‹æ›²çº¿å¯¹æ¯”
ax2 = fig.add_subplot(2, 2, 2)
ax2.plot(train_years, train_values, 'ko-', label='Training Data', markersize=5, alpha=0.6)
ax2.plot(test_years, test_values, 'k*-', label='Actual', markersize=15, linewidth=2.5)

colors_pred = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6', '#f39c12', '#1abc9c']
markers = ['^', 'v', 's', 'D', 'o', 'p']
for i, (name, _, _, preds, _) in enumerate(model_stats):
    ax2.plot(test_years, preds, color=colors_pred[i], marker=markers[i], 
             linestyle='--', label=name, markersize=10, linewidth=1.5, alpha=0.8)

ax2.axvline(x=2023.5, color='gray', linestyle=':', alpha=0.7, linewidth=2)
ax2.set_xlabel('Year', fontsize=12)
ax2.set_ylabel('Enrollment (10k persons)', fontsize=12)
ax2.set_title('All Models Prediction Comparison', fontsize=13, fontweight='bold')
ax2.legend(loc='upper left', fontsize=9, ncol=2)
ax2.grid(True, alpha=0.3)
ax2.set_xlim(2010, 2028)

# å­å›¾3ï¼šæœ€ä½³æ¨¡å‹è¯¦ç»†é¢„æµ‹
ax3 = fig.add_subplot(2, 2, 3)
best_name, best_rmse, best_mae, best_preds, _ = model_stats[0]

ax3.plot(train_years, train_values, 'bo-', label='Training', markersize=6)
ax3.plot(test_years, test_values, 'gs-', label='Actual', markersize=12, linewidth=2)
ax3.plot(test_years, best_preds, 'r^--', label=f'{best_name}', markersize=12, linewidth=2)

for yr, true, pred in zip(test_years, test_values, best_preds):
    ax3.annotate(f'P:{pred:.0f}\nA:{true:.0f}', xy=(yr, max(pred, true)), 
                 xytext=(yr+0.2, max(pred, true)+20), fontsize=9)

ax3.axvline(x=2023.5, color='gray', linestyle=':', alpha=0.7)
ax3.set_xlabel('Year', fontsize=12)
ax3.set_ylabel('Enrollment (10k persons)', fontsize=12)
ax3.set_title(f'Best Model: {best_name} (RMSE={best_rmse:.1f})', fontsize=13, fontweight='bold')
ax3.legend(loc='upper left', fontsize=10)
ax3.grid(True, alpha=0.3)

# å­å›¾4ï¼šç»“è®ºæ€»ç»“
ax4 = fig.add_subplot(2, 2, 4)
ax4.axis('off')

conclusions = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              æ¶ˆ è å® éªŒ ç»“ è®º (Ablation Study)                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                   â•‘
â•‘  ğŸ“Š å®éªŒè®¾ç½®                                                      â•‘
â•‘     â€¢ è®­ç»ƒé›†: 2005-2023å¹´ (19ä¸ªæ ·æœ¬)                             â•‘
â•‘     â€¢ æµ‹è¯•é›†: 2024-2026å¹´ (3ä¸ªæ ·æœ¬, ä¸‹é™è¶‹åŠ¿)                    â•‘
â•‘     â€¢ å¯¹æ¯”æ¨¡å‹: 6ç§ (çº¿æ€§/å¤šé¡¹å¼/SVR/RF/GBR/GPR)                 â•‘
â•‘                                                                   â•‘
â•‘  ğŸ† æœ€ä½³æ¨¡å‹: {best_name:<15}                                       â•‘
â•‘     â€¢ RMSE: {best_rmse:.1f} ä¸‡äºº                                    â•‘
â•‘     â€¢ MAE:  {best_mae:.1f} ä¸‡äºº                                     â•‘
â•‘                                                                   â•‘
â•‘  ğŸ“ˆ å…³é”®å‘ç°                                                      â•‘
â•‘     1. çº¯æ—¶åºå¤–æ¨éš¾ä»¥é¢„æµ‹æ‹ç‚¹ï¼ˆæ‰€æœ‰æ¨¡å‹éƒ½é«˜ä¼°ï¼‰                  â•‘
â•‘     2. GPRæä¾›ç½®ä¿¡åŒºé—´ï¼Œèƒ½é‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§                       â•‘
â•‘     3. çº¿æ€§æ¨¡å‹åœ¨æ­¤åœºæ™¯RMSEæœ€ä½ï¼ˆå› å¢é•¿é¢„æµ‹è¾ƒä¿å®ˆï¼‰              â•‘
â•‘     4. å¤æ‚æ¨¡å‹(RF/GBR)æ˜“è¿‡æ‹Ÿåˆæœ€åå‡ å¹´çš„ä¸Šå‡è¶‹åŠ¿                â•‘
â•‘                                                                   â•‘
â•‘  ğŸ’¡ å®è·µå»ºè®®                                                      â•‘
â•‘     â€¢ ç»“åˆé¢†åŸŸçŸ¥è¯†ï¼šåŠ å…¥å°±ä¸šç‡ã€å‡ºç”Ÿç‡ç­‰å¤–éƒ¨ç‰¹å¾                 â•‘
â•‘     â€¢ ä½¿ç”¨GPRè·å–é¢„æµ‹ç½®ä¿¡åº¦                                      â•‘
â•‘     â€¢ æ¶ˆèå®éªŒæ˜¯éªŒè¯æ–¹æ³•æœ‰æ•ˆæ€§çš„æ ‡å‡†åšæ³•                         â•‘
â•‘                                                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
ax4.text(0.02, 0.98, conclusions, transform=ax4.transAxes, fontsize=10,
         verticalalignment='top', fontfamily='monospace',
         bbox=dict(boxstyle='round', facecolor='#f0f0f0', alpha=0.9))

plt.tight_layout()
plt.savefig('ablation_study.png', dpi=300, bbox_inches='tight')
plt.savefig('ablation_study.pdf', bbox_inches='tight')
plt.savefig('ablation_study.svg', bbox_inches='tight')
plt.show()
```

### ğŸ“Š æ¶ˆèå®éªŒè®¾è®¡åŸåˆ™

| åŸåˆ™ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **å•ä¸€å˜é‡** | æ¯æ¬¡åªæ”¹å˜ä¸€ä¸ªå› ç´  | åªæ¢æ ¸å‡½æ•°ï¼Œå…¶ä»–ä¸å˜ |
| **åŸºçº¿å¯¹æ¯”** | å»ºç«‹æ˜ç¡®çš„Baseline | çº¿æ€§å›å½’ä½œä¸ºåŸºçº¿ |
| **å…¬å¹³æ¯”è¾ƒ** | ç›¸åŒçš„æ•°æ®åˆ’åˆ†å’Œè¯„ä¼°æŒ‡æ ‡ | éƒ½ç”¨RMSEè¯„ä¼° |
| **ç»Ÿè®¡æ˜¾è‘—æ€§** | å¤šæ¬¡å®éªŒå–å¹³å‡ | 5-foldäº¤å‰éªŒè¯ |
| **å®Œæ•´è®°å½•** | è®°å½•æ‰€æœ‰å®éªŒé…ç½® | å†™æ¸…æ¥šè¶…å‚æ•° |

### ğŸ“ è®ºæ–‡ä¸­æ¶ˆèå®éªŒçš„å†™æ³•

```
è¡¨1ï¼šæ¶ˆèå®éªŒç»“æœ

| Model          | RMSE  | MAE   | 
|----------------|-------|-------|
| Linear (Base)  | 60.0  | 53.3  |
| + Polynomial   | 205.2 | 186.9 |
| + SVR          | 101.4 | 81.8  |
| + GPR          | 135.2 | 126.8 |

ä»è¡¨1å¯ä»¥çœ‹å‡ºï¼Œçº¿æ€§æ¨¡å‹ä½œä¸ºåŸºçº¿åœ¨æ­¤æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³(RMSE=60.0)ï¼Œ
è¿™è¡¨æ˜è¯¥æ—¶é—´åºåˆ—çš„çŸ­æœŸé¢„æµ‹å¯ä»¥é€šè¿‡ç®€å•æ¨¡å‹è¾ƒå¥½åœ°å®Œæˆã€‚
```

---

## 15. AIè¾…åŠ©ç¼–ç¨‹å·¥å…·ï¼šTRAE

### ğŸ“Œ ä»€ä¹ˆæ˜¯TRAEï¼Ÿ

TRAE (Trae AI) æ˜¯åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„AIè¾…åŠ©ç¼–ç¨‹å·¥å…·ï¼Œæ•´åˆè‡ªç„¶è¯­è¨€ç†è§£ã€ä»£ç ç”Ÿæˆç­‰èƒ½åŠ›ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿå®Œæˆç¼–ç¨‹ä»»åŠ¡ã€è§£å†³æŠ€æœ¯é—®é¢˜ã€‚

### ğŸš€ æ ¸å¿ƒåŠŸèƒ½

| åŠŸèƒ½ç±»åˆ« | å…·ä½“èƒ½åŠ› | åº”ç”¨åœºæ™¯ |
|----------|----------|----------|
| ä»£ç ç”Ÿæˆ | ç”Ÿæˆå®Œæ•´è„šæœ¬å’Œå‡½æ•° | é¡¹ç›®åˆå§‹åŒ–ã€ç®—æ³•ç¼–å†™ |
| ä»£ç è§£é‡Š | è¯¦ç»†è§£é‡Šä»£ç é€»è¾‘ | ä»£ç å®¡æŸ¥ã€å­¦ä¹ æ–°ä»£ç  |
| é”™è¯¯ä¿®å¤ | å®šä½å¹¶ä¿®å¤é”™è¯¯ | è°ƒè¯•ã€è§£å†³è¿è¡Œæ—¶é—®é¢˜ |
| æ–‡æ¡£ç”Ÿæˆ | åˆ›å»ºé¡¹ç›®æ–‡æ¡£ | APIæ–‡æ¡£ã€ä½¿ç”¨è¯´æ˜ |
| ä»£ç é‡æ„ | ä¼˜åŒ–ä»£ç ç»“æ„ | æé«˜ä»£ç è´¨é‡ã€å¯ç»´æŠ¤æ€§ |
| æŠ€æœ¯é—®ç­” | è§£ç­”æŠ€æœ¯é—®é¢˜ | æŠ€æœ¯é€‰å‹ã€æœ€ä½³å®è·µ |

### ğŸ“ åœ¨æœ¬é¡¹ç›®ä¸­çš„åº”ç”¨
[æ•°æ®è·å–](#1-æ•°æ®è·å–) çš„éƒ¨åˆ†åŸæœ¬æ˜¯å•ç‹¬åœ¨ç›®å½•åé¢çš„å†…å®¹ä¹‹å¤–çš„ï¼Œæˆ‘æŠŠå®ƒæ”¾åœ¨äº†æœ€å‰é¢ï¼Œåé¢æ„Ÿè§‰ä¸å¦¥ï¼Œå°±æƒ³æ”¾åˆ°æ­£æ–‡é‡Œé¢ï¼Œä½†å¦‚æœæ”¾åœ¨æ­£æ–‡é‡Œé¢ç›®å½•å°±å¾—ä¸€ä¸ªä¸ªæ”¹ï¼Œå› ä¸ºç›®å½•æ˜¯æ‰‹åŠ¨ç”Ÿæˆçš„ï¼Œåœ¨1. åŠ å…¥å†…å®¹åé¢çš„åºå·éƒ½éœ€è¦å˜ï¼Œæ‰‹åŠ¨ä¸€ä¸ªä¸ªè°ƒè€—æ—¶è´¹åŠ›ï¼Œçº¯é‡å¤æ€§æ— è„‘åŠ›æ´»åŠ¨ï¼Œå€ŸåŠ© `TRAE` ï¼Œæä¾›æ­£ç¡®çš„ `prompt` ï¼ŒTRAEå°±èƒ½è‡ªåŠ¨ä¿®æ”¹ä»£ç ï¼Œæé«˜å·¥ä½œæ•ˆç‡ã€‚

### ğŸ¯ ä¼˜åŠ¿ç‰¹ç‚¹

- **é«˜æ•ˆæ€§**ï¼šå¿«é€Ÿç”Ÿæˆä»£ç ï¼Œå‡å°‘é‡å¤å·¥ä½œ
- **å‡†ç¡®æ€§**ï¼šåŸºäºæœ€æ–°æŠ€æœ¯çŸ¥è¯†ï¼Œæä¾›å¯é å»ºè®®
- **æ˜“ç”¨æ€§**ï¼šè‡ªç„¶è¯­è¨€äº¤äº’ï¼Œé™ä½ä½¿ç”¨é—¨æ§›
- **å­¦ä¹ æ€§**ï¼šç”Ÿæˆçš„ä»£ç åŒ…å«æœ€ä½³å®è·µï¼Œå¸®åŠ©å­¦ä¹ 
- **é€‚åº”æ€§**ï¼šæ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€å’ŒæŠ€æœ¯æ ˆ

![TRAE.png](TRAE.png)

## by the way

[å­¦æœ¯å†™ä½œï¼šLaTeXä¸Overleaf](#12-å­¦æœ¯å†™ä½œlatexä¸overleaf) LaTexå°±æä¾›äº†éå¸¸æ–¹ä¾¿çš„ç›®å½•ï¼Œå›¾ç›®å½•ï¼Œè¡¨ç›®å½•ï¼Œç®—æ³•ç›®å½•çš„ç”Ÿæˆå‘½ä»¤ã€‚

| ç›®å½•ç±»å‹ | æ ¸å¿ƒå‘½ä»¤ | å‘½ä»¤è¯´æ˜ | æ³¨æ„äº‹é¡¹ |
| :--- | :--- | :--- | :--- |
| **æ–‡æ¡£ç›®å½•** | `\tableofcontents` | ç”Ÿæˆå…¨æ–‡ç« èŠ‚æ ‡é¢˜çš„ç›®å½• | 1. éœ€é…åˆ `\section` `\chapter` ç­‰å±‚çº§å‘½ä»¤<br>2. é€šå¸¸æ”¾åœ¨ `\maketitle` ä¹‹åï¼Œéœ€ç¼–è¯‘ 2 æ¬¡æ‰èƒ½ç”Ÿæ•ˆ |
| **å›¾ç›®å½•** | `\listoffigures` | ç”Ÿæˆæ‰€æœ‰å›¾ç‰‡çš„ç›®å½•ï¼Œæ ‡é¢˜å–è‡ª `\caption` | 1. ä¾èµ– `figure` ç¯å¢ƒå’Œ `\caption` å‘½ä»¤<br>2. å¯é€šè¿‡ `\renewcommand{\listfigurename}{è‡ªå®šä¹‰åç§°}` ä¿®æ”¹ç›®å½•æ ‡é¢˜ï¼ˆå¦‚â€œæ’å›¾ç›®å½•â€ï¼‰ |
| **è¡¨ç›®å½•** | `\listoftables` | ç”Ÿæˆæ‰€æœ‰è¡¨æ ¼çš„ç›®å½•ï¼Œæ ‡é¢˜å–è‡ª `\caption` | 1. ä¾èµ– `table` ç¯å¢ƒå’Œ `\caption` å‘½ä»¤<br>2. å¯é€šè¿‡ `\renewcommand{\listtablename}{è‡ªå®šä¹‰åç§°}` ä¿®æ”¹ç›®å½•æ ‡é¢˜ï¼ˆå¦‚â€œè¡¨æ ¼ç›®å½•â€ï¼‰ |
| **ç®—æ³•ç›®å½•** | `\listofalgorithms` | ç”Ÿæˆæ‰€æœ‰ç®—æ³•çš„ç›®å½•ï¼Œæ ‡é¢˜å–è‡ª `\caption` | 1. éœ€å¯¼å…¥ `algorithm` æˆ– `algorithm2e` å®åŒ…<br>2. ç®—æ³•å†…å®¹éœ€æ”¾åœ¨ `algorithm` ç¯å¢ƒä¸­<br>3. å¯é€šè¿‡ `\renewcommand{\listalgorithmname}{è‡ªå®šä¹‰åç§°}` ä¿®æ”¹ç›®å½•æ ‡é¢˜ï¼ˆå¦‚â€œç®—æ³•ç›®å½•â€ï¼‰ |

---

### ä½¿ç”¨ç¤ºä¾‹
```latex
\documentclass{book}
\usepackage{algorithm}  % ç®—æ³•ç¯å¢ƒåŸºç¡€å®åŒ…
\usepackage{algorithmic} % ç®—æ³•ä¼ªä»£ç æ ¼å¼å®åŒ…
\usepackage{ctex} % æ”¯æŒä¸­æ–‡
\usepackage{graphicx}   % å›¾ç‰‡å¤„ç†å®åŒ…ï¼ˆå ä½ç¬¦ä¹Ÿå¯ä¾èµ–æ­¤åŒ…ï¼‰

\begin{document}
\maketitle

% ç”Ÿæˆå„ç±»ç›®å½•
\tableofcontents    % æ–‡æ¡£ç›®å½•
\clearpage

\listoffigures      % å›¾ç›®å½•
\clearpage

\listoftables       % è¡¨ç›®å½•
\clearpage

\listofalgorithms   % ç®—æ³•ç›®å½•
\clearpage

\chapter{ç¬¬ä¸€ç« }
\section{ç¬¬ä¸€èŠ‚}

% æ’å…¥å›¾ç‰‡å ä½ç¬¦ï¼ˆæ›¿ä»£å®é™…å›¾ç‰‡ï¼‰
\begin{figure}[h]
    \centering
    % ç”Ÿæˆ 8cm å®½ã€5cm é«˜çš„ç°è‰²å ä½çŸ©å½¢
    \rule{8cm}{5cm}
    \caption{ç¤ºä¾‹å›¾ç‰‡å ä½ç¬¦}
    \label{fig:example}
\end{figure}

% æ’å…¥è¡¨æ ¼ï¼ˆç”¨äºè¡¨ç›®å½•ï¼‰
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        åºå· & å†…å®¹ \\
        \hline
        1 & æµ‹è¯•æ•°æ® \\
        \hline
        2 & éªŒè¯æ•°æ® \\
        \hline
    \end{tabular}
    \caption{ç¤ºä¾‹è¡¨æ ¼}
    \label{tab:example}
\end{table}

% æ’å…¥ç®—æ³•ï¼ˆç”¨äºç®—æ³•ç›®å½•ï¼‰
\begin{algorithm}[h]
    \caption{ä¸¤æ•°ç›¸åŠ ç¤ºä¾‹ç®—æ³•}
    \label{alg:example}
    \begin{algorithmic}[1]
        \STATE \textbf{Input}: $a, b$ (ä¸¤ä¸ªæ•´æ•°)
        \STATE \textbf{Output}: $sum = a + b$
        \STATE $sum \gets a + b$
        \RETURN $sum$
    \end{algorithmic}
\end{algorithm}

\end{document}
```
ä½ å¯ä»¥å¤åˆ¶åˆ° [Overleaf](https://www.overleaf.com) é‡Œé¢è¯•è¯•ã€‚
> å¦‚æœéœ€è¦ç¼–è¯‘ä¸­æ–‡ï¼Œéœ€è¦ä½¿ç”¨XeLatexç¼–è¯‘å™¨ï¼Œå¹¶å¯¼å…¥{ctex}å®åŒ…ï¼Œå³\usepackage{ctex}ã€‚
> ç¼–è¯‘å™¨ç‰ˆæœ¬å¹´ä»½ä¸ç”¨é€‰æœ€æ–°çš„ï¼Œç¨³å®šçš„å°±å¾ˆå¥½ç”¨ï¼Œä¸€äº›è«åå…¶å¦™çš„bugæœ‰æ—¶å€™æŠŠç¼–è¯‘å™¨ç‰ˆæœ¬è°ƒä½å°±å¯ä»¥è§£å†³ã€‚
> ![ctex1.png](ctex1.png)
> ![ctex2.png](ctex2.png)
> ![ctex3.png](ctex3.png)


---

## 16. é™„å½•ï¼šå¸¸ç”¨å‘½ä»¤é€ŸæŸ¥è¡¨

### Condaç¯å¢ƒç®¡ç†
```bash
conda create -n env_name python=3.10  # åˆ›å»ºç¯å¢ƒ
conda activate env_name                # æ¿€æ´»ç¯å¢ƒ
conda deactivate                       # é€€å‡ºç¯å¢ƒ
conda env list                         # åˆ—å‡ºæ‰€æœ‰ç¯å¢ƒ
conda env remove -n env_name           # åˆ é™¤ç¯å¢ƒ
conda env export > env.yml             # å¯¼å‡ºç¯å¢ƒ
conda env create -f env.yml            # ä»æ–‡ä»¶åˆ›å»º
```

### PipåŒ…ç®¡ç†
```bash
pip install package_name               # å®‰è£…åŒ…
pip install -r requirements.txt        # ä»æ–‡ä»¶å®‰è£…
pip freeze > requirements.txt          # å¯¼å‡ºä¾èµ–
pip uninstall package_name             # å¸è½½åŒ…
```

### Gitç‰ˆæœ¬æ§åˆ¶
```bash
git init                               # åˆå§‹åŒ–ä»“åº“
git clone url                          # å…‹éš†ä»“åº“
git add .                              # æ·»åŠ æ‰€æœ‰æ–‡ä»¶
git commit -m "message"                # æäº¤
git push origin main                   # æ¨é€
git pull                               # æ‹‰å–æ›´æ–°
```

### Matplotlibä¿å­˜å›¾åƒ
```python
# æ˜¾å¼è®¾ç½®dpiï¼Œä¿å­˜å¤šç§æ ¼å¼
plt.savefig('fig.png', dpi=300, bbox_inches='tight')
plt.savefig('fig.pdf', bbox_inches='tight')  # çŸ¢é‡æ ¼å¼
plt.savefig('fig.svg', bbox_inches='tight')  # çŸ¢é‡æ ¼å¼
```

---

## ğŸ“ é‡åˆ°é—®é¢˜ï¼Ÿ

å®‰è£…è¿‡ç¨‹ä¸­å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿éšæ—¶[è”ç³»æˆ‘ï¼](karcenzheng@yeah.net)

**ç¥é¡ºåˆ©ï¼ğŸ‰**

---

*æœ€åæ›´æ–°ï¼š2026å¹´1æœˆ*
